# 1. 数仓分层

## 1.1 数仓分层简介

ODS(Original Data Store)：原始数据层，原始数据原封不动直接导入。

DWD(Data Warehouse Detail)：基于ODS层，将原始数据进行清洗、筛选后，把筛选后数据的明细展开。例如：启动日志原始数据是 { t:xxx,ba:xx }，展开后可以获取具体每个字段的值。

DWS(Data Warehouse Service)：为后续的分析提供数据服务，基于 DWD 层将 DWD 层数据按天进行聚合。例如：统计每天的新增用户，每天的订单量，每天的交易额等。

DWT(Data Warehouse Topic)：选择一个主题，以主题为核心，将和这个主题所有相关的核心数据进行导入。例如： 以用户为主题，将和用户相关的所有信息，例如新增用户数，用户下单数，用户评论数，用户点赞数，用户使用优惠券等信息进行汇总。

ADS(Application Data Store)：基于 DWT 层，统计具体报表需要的结果。

注意事项： 层与层之间必须依次调用，不能跨层调用。

​				数据 -----> ODS -----> DWD -----> DWS -----> DWT -----> ADS -----> 导出



## 1.2 分层的好处

① 分层解耦，可以让开发思路更清晰。把复杂问题，拆分为若干步骤，将复杂问题简单化，方便出错时精确定位。

② 避免重复开发。

③ 脱敏。



## 1.3 数据集市和数据仓库的区别

数据仓库：企业级别

数据集市：部门级别

区别： 数据集市可以是数据仓库的一个子集，数据集市在规模上远小于数据仓库。

# 2. 建模理论相关

## 2.1 范式

范式指在建模时需要遵循的规范和样式，使用范式的目的：

① 减少数据的冗余。

② 保证数据的一致性。

缺点：当需要多种类型的数据时，只能通过 Join 拼接才能得到最终的结果。



## 2.2 函数依赖

完全函数依赖： 必须由集合中的全部才可以推出另外一个集合。

部分函数依赖： 由集合的一部分就可以推出另外一个集合。

传递函数依赖： X ---> Y，Y !---> X，Y ---> Z

​						X 集合和 Z 集合本身无关系，只能通过 Y 间接产生关联。

​						如果 X 集合要和 Z 集合产生关联，需要通过 Y 进行传递关系。

​						特点： 不能反推。

## 2.3 常见的三范式

第一范式： 要求属性不可切割。

第二范式：不能存在部分函数依赖。一个表中的非主键字段必须全部完全函数依赖于主键。

第三范式：表中所有非主键字段必须直接依赖于主键，不能出现有传递函数依赖。

## 2.4 关系建模和维度建模

| **对比属性** | **OLTP**                   | **OLAP**                   |
| ------------ | -------------------------- | -------------------------- |
| **读特性**   | 每次查询只返回少量记录     | 对大量记录进行汇总         |
| **写特性**   | 随机、低延时写入用户的输入 | 批量导入                   |
| **使用场景** | 用户，Java EE项目          | 内部分析师，为决策提供支持 |
| **数据表征** | 最新数据状态               | 随时间变化的历史状态       |
| **数据规模** | GB                         | TB到PB                     |

关系建模 (ER建模)：一般用于关系型数据库的建模。特征：

​		① 将一个业务拆分的很抽象，很精细。

​		② 强调数据的治理，方便管理，保证数据的强一致性。

​		③ 完成某个需求时，需要多个表一起操作才能得到结果，强调数据的整合。

​		④ 适合更新多的场景时，保证数据的强一致性，只需要更新一次即可。

维度建模：一般用于大数据分析领域的建模。维度建模会面向某个具体的业务(主题)，将这个业务相关的数据放入到一个维度(表)中。特征：

​		① 会造成数据的冗余(主要体现在宽表中)。

​		② 好处是面向业务，这个关系结构清晰，计算时不需要过多的数据整合，效率高。

## 2.5 事实表和维度表

事实表：描述一个事实的表，称为事实表。

维度表：描述一个事实不同角度，或不同方面的表，称为维度表。

## 2.6 维度建模

星型模型：维度表直接关联在事实表上，最多只需要 Join 一次。

雪花模型：部分维度表间接关联在事实表上，可能需要多次 Join。

星座模型：星座模型本质上属于星型模型，是一种特殊的星型模型。一个星座模型中可能存在多个事实表，这些事实表，共享某个维度表。

注：一般选择星型模型。



## 2.7 事实表的分类

事务型事实表： 表中的数据一旦生成不会修改，例如交易流水。

周期型事实表： 周期型性记录某个事实，例如月销量。

累积型事实表： 追中某个事实业务的状态，会不断地修改事实记录，例如物流状态。

# 3. 数仓建模

## 3.1 ODS

ODS 数据保持原貌，可以使用压缩。

## 3.2 DWD

一般采取星型模型进行建模。过程：

① **选择业务线**

② **声明粒度**：选择最细的粒度，再由最细的粒度向粗的粒度聚合。

③ **确认维度**：围绕业务事实，选取其他的可以描述业务事实的其他表。通常一般会按照 who、where、when 的思路获取想要的信息。下单事实，除了order_info（事实表），还会选取

​		who:  user_info(用户表)

​		where:  base_region,base_province(地区表)

​		when：date_info（日期表）

还可以选取其他感兴趣的维度，例如优惠券表等。

④ **确定事实**：选取 order_info 表中的一些可以度量的字段进行建表，例如订单金额等。另外，会将维度表在进行维度建模时降维。

|                | **时间** | **用户** | **地区** | **商品** | **优惠券** | **活动** | **编码** | **度量值** |
| -------------- | -------- | -------- | -------- | -------- | ---------- | -------- | -------- | ---------- |
| **订单**       | √        | √        | √        |          |            | √        |          | 件数/金额  |
| **订单详情**   | √        |          | √        | √        |            |          |          | 件数/金额  |
| **支付**       | √        |          | √        |          |            |          |          | 金额       |
| **加购**       | √        | √        |          | √        |            |          |          | 件数/金额  |
| **收藏**       | √        | √        |          | √        |            |          |          | 个数       |
| **评价**       | √        | √        |          | √        |            |          |          | 个数       |
| **退款**       | √        | √        |          | √        |            |          |          | 件数/金额  |
| **优惠券领用** | √        | √        |          |          | √          |          |          | 个数       |

之后将事实和维度放入1个2维表格中，勾选需要进行关联的项目；确定关联的 ID 和度量值。

## 3.3 其他层

DWT 和 DWS 和 ADS 都是根据业务需要创建宽表。

## 3.4 总结

ODS层： 2张用户行为表 (启动日志+事件日志)

​				24 张业务数据表

DWD层：由 ODS 的24张业务数据表导入，变为 8个事实表+7个维度表

​				由2张用户行为表 (启动日志+事件日志) 导入变为 1张启动日志表+11张不同的事件表

DWS层： 选取六个不同的主题，创建6张表

DWT层： 选择4个主题，创建4张表

ADS层： 有几个需求，就创建几张表

# 4. 导入数据

## 4.1 ODS 层

### 4.1.1 用户行为数据

建库

```sql
show databases;
create database gmall;
use gmall;
```

建表

```sql
drop table if exists ods_start_log;
CREATE EXTERNAL TABLE ods_start_log (`line` string)
PARTITIONED BY (`dt` string)
STORED AS
  INPUTFORMAT 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'
  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION '/warehouse/gmall/ods/ods_start_log';
```

导入数据

```sql
load data inpath '/origin_data/gmall/log/topic_start/2020-03-03' into table gmall.ods_start_log partition(dt='2020-03-03');
```

为 lzo 文件创建索引

```bash
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /warehouse/gmall/ods/ods_start_log/dt=2020-03-03
```

### 4.1.2 启动日志数据

思路同上，不再赘述。

### 4.1.3 ODS 层加载日志数据脚本

```shell
#!/bin/bash
#1. 确定要导入数据的日期
if [ -n "$1" ]
then 
	do_date=$1
else
	do_date=$(date -d 'yesterday' '+%F')
fi

#2. 导入命令 hive默认连接的是default库，如果要使用别的库，请先使用use，或用库名.表名/函数名声明

sql="
use gmall;

load data inpath '/origin_data/gmall/log/topic_start/$do_date' overwrite into table ods_start_log partition(dt='$do_date');

load data inpath '/origin_data/gmall/log/topic_event/$do_date' overwrite into table ods_event_log partition(dt='$do_date');
"
#3. 执行sql
hive -e "$sql"

#4. 为导入的数据创建索引
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /warehouse/gmall/ods/ods_start_log/dt=$do_date
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /warehouse/gmall/ods/ods_event_log/dt=$do_date

```

### 4.1.4 ODS 层加载业务数据脚本

建表语句见参考文档，脚本如下。

```shell
#!/bin/bash
#hdfs_ods_db.sh first或all 日期
if [ $1 != first ] && [ $1 != all ]
then
        echo 第一个参数必须为first或all！
        exit;
fi

#1. 确定要导入数据的日期
if [ -n "$2" ]
then 
	do_date=$2
else
	do_date=$(date -d 'yesterday' '+%F')
fi

#2. 导入命令 hive默认连接的是default库，如果要使用别的库，请先使用use，或用库名.表名/函数名声明
APP=gmall

sql="
load data inpath '/origin_data/$APP/db/order_info/$do_date' OVERWRITE into table ${APP}.ods_order_info partition(dt='$do_date');

load data inpath '/origin_data/$APP/db/order_detail/$do_date' OVERWRITE into table ${APP}.ods_order_detail partition(dt='$do_date');

load data inpath '/origin_data/$APP/db/sku_info/$do_date' OVERWRITE into table ${APP}.ods_sku_info partition(dt='$do_date');

load data inpath '/origin_data/$APP/db/user_info/$do_date' OVERWRITE into table ${APP}.ods_user_info partition(dt='$do_date');

load data inpath '/origin_data/$APP/db/payment_info/$do_date' OVERWRITE into table ${APP}.ods_payment_info partition(dt='$do_date');

load data inpath '/origin_data/$APP/db/base_category1/$do_date' OVERWRITE into table ${APP}.ods_base_category1 partition(dt='$do_date');

load data inpath '/origin_data/$APP/db/base_category2/$do_date' OVERWRITE into table ${APP}.ods_base_category2 partition(dt='$do_date');

load data inpath '/origin_data/$APP/db/base_category3/$do_date' OVERWRITE into table ${APP}.ods_base_category3 partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/base_trademark/$do_date' OVERWRITE into table ${APP}.ods_base_trademark partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/activity_info/$do_date' OVERWRITE into table ${APP}.ods_activity_info partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/activity_order/$do_date' OVERWRITE into table ${APP}.ods_activity_order partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/cart_info/$do_date' OVERWRITE into table ${APP}.ods_cart_info partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/comment_info/$do_date' OVERWRITE into table ${APP}.ods_comment_info partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/coupon_info/$do_date' OVERWRITE into table ${APP}.ods_coupon_info partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/coupon_use/$do_date' OVERWRITE into table ${APP}.ods_coupon_use partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/favor_info/$do_date' OVERWRITE into table ${APP}.ods_favor_info partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/order_refund_info/$do_date' OVERWRITE into table ${APP}.ods_order_refund_info partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/order_status_log/$do_date' OVERWRITE into table ${APP}.ods_order_status_log partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/spu_info/$do_date' OVERWRITE into table ${APP}.ods_spu_info partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/activity_rule/$do_date' OVERWRITE into table ${APP}.ods_activity_rule partition(dt='$do_date'); 

load data inpath '/origin_data/$APP/db/base_dic/$do_date' OVERWRITE into table ${APP}.ods_base_dic partition(dt='$do_date');

"
#导入省份表和地区表
sql2="
load data inpath '/origin_data/$APP/db/base_province/$do_date' OVERWRITE into table ${APP}.ods_base_province;

load data inpath '/origin_data/$APP/db/base_region/$do_date' OVERWRITE into table ${APP}.ods_base_region;

"

#3. 执行sql
if [ $1 = first ]
then
	hive -e "$sql2"
fi

hive -e "$sql"

```





#### 4.1.5 函数 get_json_object 介绍

get_json_object(json_txt, path) - Extract a json object from path 
Extract json object from a json string based on json path specified, and return json string of the extracted json object. It will return null if the input json string is invalid.
A limited version of JSONPath supported:
  $  : Root object
  .   : Child operator
  []  : Subscript operator for array

函数需要传入两个函数，分别为 json 字符串及解析的 path。一旦传入的 json 字符串非法，返回 null 值。Path 中

​	$ : 代表json的根对象

​	.  : 子属性操作符

​	[] : 代表 json array 的下角标操作符

### 4.1.6 配置远程工具访问 hiveserver2

编辑 hdfs-site.xml，添加如下属性：

```xml
<property>  
<name>dfs.webhdfs.enabled</name>  
<value>true</value>  
</property> 
```

编辑 core-site.xml 添加如下属性：

```xml
<property>
<name>hadoop.proxyuser.atguigu.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.atguigu.groups</name>
<value>*</value>
</property>
```

分发后重启。

## 4.2 DWD 层

### 4.2.1  DWD 层用户行为数据

#### 4.2.1.1 dwd_start_log

建表

```sql
drop table if exists dwd_start_log;
CREATE EXTERNAL TABLE dwd_start_log(
`mid_id` string,
`user_id` string, 
`version_code` string, 
`version_name` string, 
`lang` string, 
`source` string, 
`os` string, 
`area` string, 
`model` string,
`brand` string, 
`sdk_version` string, 
`gmail` string, 
`height_width` string,  
`app_time` string,
`network` string, 
`lng` string, 
`lat` string, 
`entry` string, 
`open_ad_type` string, 
`action` string, 
`loading_time` string, 
`detail` string, 
`extend1` string
)
PARTITIONED BY (dt string)
stored as parquet
location '/warehouse/gmall/dwd/dwd_start_log/'
TBLPROPERTIES('parquet.compression'='lzo');

```

注意：parquet 和 orc 的任何压缩格式都可以切片，因为它是在行组内部进行压缩的。

启动日志 start_log 的每一条均为简单 json 对象，类似于 hashmap 数据结构。因此只需调用 get_json_object 函数即可对其进行解析，并将数据导入建好的表中即可。

```sql
insert overwrite TABLE dwd_start_log PARTITION(dt='2020-03-29')
SELECT
    get_json_object(line,"$.mid") mid_id,
    get_json_object(line,"$.uid") user_id,
    get_json_object(line,"$.vc") version_code,
    get_json_object(line,"$.vn") version_name,
    get_json_object(line,"$.l") lang,
    get_json_object(line,"$.sr") source,
    get_json_object(line,"$.os") os,
    get_json_object(line,"$.ar") area,
    get_json_object(line,"$.md") model,
    get_json_object(line,"$.ba") brand,
    get_json_object(line,"$.sv") sdk_version,
    get_json_object(line,"$.g") gmail,
    get_json_object(line,"$.hw") height_width,
    get_json_object(line,"$.t") app_time,
    get_json_object(line,"$.nw") network,
    get_json_object(line,"$.ln") lng,
    get_json_object(line,"$.la") lat,
    get_json_object(line,"$.entry") entry,
    get_json_object(line,"$.open_ad_type") open_ad_type,
    get_json_object(line,"$.action") action,
    get_json_object(line,"$.loading_time") loading_time,
    get_json_object(line,"$.detail") detail,
    get_json_object(line,"$.extend1") extend1
FROM ods_start_log
WHERE dt='2020-03-29'
```

#### 4.2.1.2 自定义函数分析

DWD 层的事件日志 event_log 同样需要从 ods 层查询后导入。与 start_log 不同的是，event_log 存在 Json 对象的嵌套，而且导出后还要对每条数据中的多个 event 进行侧写（lateralview）。

ODS 层 ods_event_log 表的 line 列数据格式为：时间戳 | {"ap":xxx,"cm":{  },"et":[{},{},{}]  }。

ods_event_log ---> dwd_base_event_log：将 ods_event_log 的时间戳解析；将 cm 中的公共字段进行解析解析；需要将 et 中的每个事件，按照事件名和事件的 json 字符串一一对应。

dwd_base_event_log 为各个事件表。根据事件名称，查询出所有此名称的事件，导入到对应的事件表。需要定义辅助的函数，帮助完成 ods_event_log ---> dwd_base_event_log 的数据解析功能。

**UDF 函数： 一进一出。**假设函数名为 base_analizer(data, property)，需实现功能：

​	① 当传入 ods_event_log 的一行数据，再传入 ts，返回时间戳部分。例如：

​			base_analizer(时间戳 | {"ap":xxx,"cm":{  },"et":[{},{},{}]  }, ts) 返回 时间戳 字符串；

​	② 当传入 ods_event_log 的一行数据，再传入 cm 中的某个属性名时，返回 cm 中的对应的属性值。例如：

​			base_analizer(时间戳 | {"ap":xxx,"cm":{  },"et":[{},{},{}]  }, la) 返回 EN 字符串；

​	③ 当传入 ods_event_log 的一行数据，再传入 et 时，返回整个事件的数组字符串，例如：

​			base_analizer(时间戳 | {"ap":xxx,"cm":{  },"et":[{},{},{}]  }, et) 返回 [{},{}]；

​	④ 当传入 ods_event_log 的一行数据，再传入 ap 时，返回 ap 对应的属性值，例如：

​			base_analizer(时间戳 | {"ap":xxx,"cm":{  },"et":[{},{},{}]  }, ap) 返回 xxx；

**UDTF函数： 一进多出。**假设函数名为 base_analizer(data)，需实现功能：

​		传入一个 json 数组的字符串 [{},{}] ，返回N行2列，且这两列分别为数组中的事件名称和对应的事件的JSON字符串。例如： b( [{},{},{}] ) 返回 

​						a事件, {}

​						b事件, {}

​						c事件, {}

#### 4.2.1.3 自定义函数实现

##### 4.2.1.3.1 环境的配置

华为云镜像仓库配置

```xml
<servers>
<server>
    <id>huaweicloud</id>
    <username>anonymous</username>
    <password>devcloud</password>
</server>
</servers>

<mirrors>
 <mirror>
    <id>huaweicloud</id>
    <mirrorOf>*</mirrorOf>
    <url>https://mirrors.huaweicloud.com/repository/maven/</url>
</mirror>
</mirrors>
```

##### 4.2.1.3.2 UDF

```java
package com.atguigu.hive.functions;

import org.apache.hadoop.hive.ql.exec.UDF;
import org.json.JSONObject;

/**
 * Created by VULCAN on 2020/4/2
 *
 * 提供多个evaluate()，方法必须有返回值，不能为void，可以返回null!
 *  ①传入ts，返回时间戳部分
 *  ②传入cm中的某个属性名，返回其属性值
 *  ③传入et，返回[{},{}]
 *
 */
public class MyUDF extends UDF {

    public  String evaluate(String source,String param){

        //对param进行校验，param必须是ts或et或cm中的某个属性名才合法
        if (!source.contains(param) && !"ts".equals(param)){
            return null;
        }

        //param合法，取出对应的参数值
        String[] words = source.split("\\|");
        //将|后面的部分构建为json object
        JSONObject root = new JSONObject(words[1]);
        //如果请求的是时间戳
        if ("ts".equals(param)){
            return words[0];
        }else if ("ap".equals(param)){
            return  root.getString("ap");
        }else if ("et".equals(param)){
            return  root.getString("et");
        }else{
            //取cm中的某个属性值
            return root.getJSONObject("cm").getString(param);
        }
    }
}

```

测试：

```java
@org.junit.Test
    public void evaluate() {

        String str="1586620821601|{\"cm\":{\"ln\":\"-109.2\",\"sv\":\"V2.2.5\",\"os\":\"8.2.7\",\"g\":\"86I0Y26Y@gmail.com\",\"mid\":\"3\",\"nw\":\"4G\",\"l\":\"es\",\"vc\":\"17\",\"hw\":\"750*1134\",\"ar\":\"MX\",\"uid\":\"3\",\"t\":\"1586583920981\",\"la\":\"-43.6\",\"md\":\"Huawei-1\",\"vn\":\"1.3.9\",\"ba\":\"Huawei\",\"sr\":\"L\"},\"ap\":\"app\",\"et\":[{\"ett\":\"1586595823882\",\"en\":\"ad\",\"kv\":{\"activityId\":\"1\",\"displayMills\":\"84470\",\"entry\":\"1\",\"action\":\"1\",\"contentType\":\"0\"}},{\"ett\":\"1586525960461\",\"en\":\"active_background\",\"kv\":{\"active_source\":\"3\"}}]}";

        System.out.println(new MyUDF().evaluate(str,"ln"));

    }
```

##### 4.2.1.3.3 UDTF

① 继承 GenericUDTF ，实现`initialize`, `process`，可以选择性实现 close()。

② initialize 被定义后，会 hive 自动调用，调用时 hive 通过这个函数检查 UDTF 参数是否是期望的参数，initialize 必须返回 UDTF 生成结果(每行每个列的)的对象检测器。对输入参数的校验也在该步骤进行。

③ initialize 在调用之后，会将函数传入的参数传递给 process()，在 process() 中完成 UDTF 函数的业务逻辑，之后再调用 forward() 将每行的处理结果提交。

④ 最后，所有的行都已经处理完毕，调用 close 方法。

```java
package com.atguigu.hive.functions;
import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
import org.apache.hadoop.hive.ql.metadata.HiveException;
import org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;
import org.apache.hadoop.hive.serde2.objectinspector.StructField;
import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
import org.json.JSONArray;
import org.json.JSONException;
import org.json.JSONObject;

import java.util.ArrayList;
import java.util.List;
/**
 * Created by VULCAN on 2020/4/2
 */
public class MyUDTF extends GenericUDTF {

    //  ①检查入参  ②返回UDTF返回的每行的每列的类型检查器
    //  Inspector： 检查器，检查员
    @Override
    public StructObjectInspector initialize(StructObjectInspector argOIs) throws UDFArgumentException {
        //获取UDTF传入的参数引用
        List<? extends StructField> inputFields = argOIs.getAllStructFieldRefs();
        //只能传入1个参数
        if (inputFields.size() != 1){
            throw  new  UDFArgumentException("参数个数只能是1个！");
        }
        //检查类型是否是String类型  string指的是hive中的string类型
        if (!"string".equals(inputFields.get(0).getFieldObjectInspector().getTypeName())) {

            throw  new UDFArgumentException("参数类型必须是string类型!");
        }
        // 返回的一行中的每一列的临时字段名
        List<String> fieldNames=new ArrayList<>();
        fieldNames.add("event_name");
        fieldNames.add("event_json");
        // 声明返回的一行中的每一列的字段类型检测器
        List<ObjectInspector> fieldOIs=new ArrayList<>();
        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);
        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);

        return ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames,
                fieldOIs);
    }

    // 完成函数的计算逻辑  b(line) 返回   2列N(参数中事件对象的个数)行
    // 参数： [{},{},{}]
    @Override
    public void process(Object[] objects) throws HiveException {

        //检查是否传入了参数
        if (objects[0]==null || objects.length==0){
            return;
        }
        //有参数，开始解析
        try {
            JSONArray jsonArray = new JSONArray(objects[0].toString());
            //取出JSON array中的每一个事件，取出事件中的每一个事件名称和事件的字符串
            for ( int i=0; i<jsonArray.length();i++){
                    //声明一个数组，存放UDTF返回的结果
                    String [ ] result=new String[2];
                    //取出事件对应的json object对象
                    JSONObject eventJO = jsonArray.getJSONObject(i);
                    //获取事件名
                    result[0]=eventJO.getString("en");
                    result[1]=eventJO.toString();
                    //将结果写出
                    // System.out.println(Arrays.asList(result));
                    forward(result);
            }
        } catch (JSONException e) {
            e.printStackTrace();
        }
    }
    //最后关闭时，执行操作
    @Override
    public void close() throws HiveException {
    }
}

```

测试时，可能会报错空指针，但是在上传到 hive 后，是没问题的。

##### 4.2.1.3.4 创建函数

① 将函数的 jar 包打包后，上传到 $HIVE_HOME/auxlib 目录。

② 启动hive，切换到 gmall 库下定义函数：

```sql
create function base_analizer1 as 'com.atguigu.hive.myfunctions.MyUDF';
create function flat_analizer1 as 'com.atguigu.hive.myfunctions.MyUDTF';
```

注意：函数的使用需要在函数定义的库，或者使用 库名.函数名 使用。

#### 4.2.1.4 dwd_base_event_log

```sql
INSERT overwrite TABLE dwd_base_event_log PARTITION(dt='2020-03-29')
SELECT 
    base_analizer(line,'mid') mid_id,
    base_analizer(line,'uid') user_id,
    base_analizer(line,'vc') version_code,
    base_analizer(line,'vn') version_name,
    base_analizer(line,'l') lang,
    base_analizer(line,'sr') source,
    base_analizer(line,'os') os,
    base_analizer(line,'ar') area,
    base_analizer(line,'md') model,
    base_analizer(line,'ba') brand,
    base_analizer(line,'sv') sdk_version,
    base_analizer(line,'g') gmail,
    base_analizer(line,'hw') height_width,
    base_analizer(line,'t') app_time,
    base_analizer(line,'nw') network,
    base_analizer(line,'ln') lng,
    base_analizer(line,'la') lat,
    event_name, event_json, 
    base_analizer(line,'ts') server_time
FROM ods_event_log
LATERAL VIEW flat_analizer(base_analizer(line,'et')) tmp as  event_name,event_json
WHERE dt='2020-03-29'
```

除了使用 UDF/ UDTF 对 ods_event_log 中的数据进行处理，可以使用 hive 内置的函数 split 结合前面介绍的 get_json_object 函数，如下：

```sql
INSERT overwrite TABLE dwd_base_event_log PARTITION(dt='2020-03-03')
SELECT
	get_json_object(split(line, '\\|')[1], '$.cm.mid') mid_id, 
	get_json_object(split(line, '\\|')[1], '$.cm.uid') user_id, 
	get_json_object(split(line, '\\|')[1], '$.cm.vc') version_code, 
	get_json_object(split(line, '\\|')[1], '$.cm.vn') version_name, 
	get_json_object(split(line, '\\|')[1], '$.cm.l') lang, 
	get_json_object(split(line, '\\|')[1], '$.cm.sr') source, 
	get_json_object(split(line, '\\|')[1], '$.cm.os') os, 
	get_json_object(split(line, '\\|')[1], '$.cm.ar') area, 
	get_json_object(split(line, '\\|')[1], '$.cm.md') model, 
	get_json_object(split(line, '\\|')[1], '$.cm.ba') brand, 
	get_json_object(split(line, '\\|')[1], '$.cm.sv') sdk_version, 
	get_json_object(split(line, '\\|')[1], '$.cm.g') gmail, 
	get_json_object(split(line, '\\|')[1], '$.cm.hw') height_width, 
	get_json_object(split(line, '\\|')[1], '$.cm.t') app_time, 
	get_json_object(split(line, '\\|')[1], '$.cm.nw') network, 
	get_json_object(split(line, '\\|')[1], '$.cm.ln') lng, 
	get_json_object(split(line, '\\|')[1], '$.cm.la') lat, 
	event_name, 
	event_json, 
	split(line, '\\|')[0] server_time
FROM ods_event_log
LATERAL VIEW flat_analizer(get_json_object(split(line, '\\|')[1], '$.et')) tmp as event_name, event_json
WHERE dt='2020-03-03'
```

任选一种方案，将语句中的日期设置为变量，通过脚本传参调用即为数据导入脚本。

#### 4.2.1.5 向dwd_事件表中导入数据

以dwd_display_log为例：

```sql
INSERT overwrite TABLE dwd_display_log PARTITION(dt='2020-03-29')
SELECT 
    mid_id, user_id, version_code, version_name, 
    lang, source, os, area, model, brand, 
    sdk_version, gmail, height_width, app_time, network, lng, lat,
    get_json_object(event_json,'$.kv.action') action, 
    get_json_object(event_json,'$.kv.goodsid') goodsid,
    get_json_object(event_json,'$.kv.place') place, 
    get_json_object(event_json,'$.kv.extend1') extend1,
    get_json_object(event_json,'$.kv.category') category, 
    server_time
FROM dwd_base_event_log
WHERE dt='2020-03-29' and event_name='display';

```

### 4.2.2 DWD 层业务数据维度表

#### 4.2.2.1 dwd_dim_sku_info

表多时，可以采取下面这种写法：

```sql
with 
表名1 as (select 语句),
表名2 as (select 语句),
表名3 as (select 语句)
select 语句
```

```sql
WITH 
t1 as
(select id category1_id,name category1_name FROM ods_base_category1 where dt='2020-03-29'), 
t2 as
(select id category2_id,name category2_name,category1_id FROM ods_base_category2 where dt='2020-03-29'),
t3 as
(select id category3_id,name category3_name,category2_id FROM ods_base_category3 where dt='2020-03-29'),
t4 as
(SELECT id spu_id, spu_name from ods_spu_info where dt='2020-03-29'),
t5 as
(SELECT tm_id , tm_name from ods_base_trademark where dt='2020-03-29'),
t6 as
(SELECT id,spu_id,price,sku_name, sku_desc ,weight, tm_id, category3_id,create_time from ods_sku_info where dt='2020-03-29')
insert overwrite table dwd_dim_sku_info PARTITION(dt='2020-03-29')
SELECT t6.id, t6.spu_id, t6.price, t6.sku_name, t6.sku_desc,
t6.weight, t6.tm_id, t5.tm_name, 
t6.category3_id, t2.category2_id, 
t1.category1_id, t3.category3_name,
t2.category2_name, t1.category1_name, t4.spu_name, t6.create_time
FROM t6 join  t5 on t6.tm_id=t5.tm_id
join t4 on t6.spu_id=t4.spu_id
join t3 on t3.category3_id=t6.category3_id
join t2 on t3.category2_id=t2.category2_id
join t1 on t1.category1_id=t2.category1_id


```

#### 4.2.2.2 dwd_dim_coupon_info

```sql
INSERT overwrite TABLE dwd_dim_coupon_info PARTITION(dt='2020-03-29')
SELECT id, coupon_name, coupon_type, condition_amount, condition_num,
activity_id, benefit_amount, benefit_discount, create_time, range_type, 
spu_id, tm_id, category3_id, limit_num, operate_time, expire_time
FROM ods_coupon_info
where dt='2020-03-29';
```

#### 4.2.2.3  dwd_dim_activity_info

```sql
INSERT overwrite table dwd_dim_activity_info PARTITION(dt='2020-03-29')
SELECT t1.id, t1.activity_name, t1.activity_type,
t2.condition_amount, t2.condition_num, t2.benefit_amount, 
t2.benefit_discount, t2.benefit_level, 
t1.start_time, t1.end_time, t1.create_time
FROM
(SELECT id,activity_name, activity_type,
start_time, end_time, create_time
FROM ods_activity_info  WHERE dt='2020-03-29') t1
JOIN
(SELECT activity_id,condition_amount, condition_num, benefit_amount, benefit_discount, 
benefit_level
FROM ods_activity_rule  WHERE dt='2020-03-29') t2
on t1.id=t2.activity_id
```

#### 4.2.2.4 dwd_dim_base_province

```sql
insert overwrite table dwd_dim_base_province 
SELECT 
    op.id, op.name province_name, area_code, iso_code, region_id, 
    region_name
FROM ods_base_province op JOIN ods_base_region `or`
on op.region_id=`or`.id;

```

#### 4.2.2.5 dwd_dim_date_info

修改建表语句：

```sql
DROP TABLE IF EXISTS `dwd_dim_date_info`;
CREATE EXTERNAL TABLE `dwd_dim_date_info`(
    `date_id` string COMMENT '日',
    `week_id` int COMMENT '周',
    `week_day` int COMMENT '周的第几天',
    `day` int COMMENT '每月的第几天',
    `month` int COMMENT '第几月',
    `quarter` int COMMENT '第几季度',
    `year` int COMMENT '年',
    `is_workday` int COMMENT '是否是周末',
    `holiday_id` int COMMENT '是否是节假日'
)
row format delimited fields terminated by '\t'
location '/warehouse/gmall/dwd/dwd_dim_date_info/';

```

```
load data local inpath '/home/atguigu/date_info.txt' overwrite into  table dwd_dim_date_info;
```

#### 4.2.2.6  dwd_dim_user_info_his

数据从和用户相关的维度表中取，主要从 ods_user_info 中取。

拉链表简介：拉取数据 + 表特征链条化变化。

场景： 数据是新增和变化，但是大部分是新增，每天的变化的概率很小且为缓慢变化。

特征： 存储全部的用户信息，不分区。可以呈现一个数据的历史变化情况。

用户表数据如何同步： 

​	① 如果用户量少，直接全量同步，覆盖掉之前的表即可。但前提是不需要查看数据的变化过程，不需要查看数据的历史记录。

​	② 如果用户量大，需要同步新增和变化的数据。那么问题来了，如何链条化地记录数据的特征变化？—— 为每条记录添加可以标识生命周期的字段，比如起始日期和结束日期；如果同步了发生变化的数据，如何对旧的数据进行修改？—— 从原始拉链表查询所有的历史数据和当天的新增变化数据进行合并，合并后先导入到一张临时拉链表，其目的是为了防止直接导入原始表发生异常时清空原始表。之后再由临时表覆盖导入到原始拉链表。

全量切片：比如获取到 1-1 的全量切片

​						select * from 拉链表 where startdate <= 1-1  and enddate >= 1-1

即选取截止到 1-1 日依然有效的数据。

数据准备：

```sql
DELETE  FROM user_info WHERE id<100;
UPDATE user_info SET `operate_time`=NULL 
```

创建拉链表：

```sql
drop table if exists dwd_dim_user_info_his;
create external table dwd_dim_user_info_his(
    `id` string COMMENT '用户id',
    `name` string COMMENT '姓名', 
    `birthday` string COMMENT '生日',
    `gender` string COMMENT '性别',
    `email` string COMMENT '邮箱',
    `user_level` string COMMENT '用户等级',
    `create_time` string COMMENT '创建时间',
    `operate_time` string COMMENT '操作时间',
    `start_date`  string COMMENT '有效开始日期',
    `end_date`  string COMMENT '有效结束日期'
) COMMENT '订单拉链表'
stored as parquet
location '/warehouse/gmall/dwd/dwd_dim_user_info_his/'
tblproperties ("parquet.compression"="lzo");

```

创建临时拉链表：

```sql
drop table if exists dwd_dim_user_info_his_tmp;
create external table dwd_dim_user_info_his_tmp(
    `id` string COMMENT '用户id',
    `name` string COMMENT '姓名', 
    `birthday` string COMMENT '生日',
    `gender` string COMMENT '性别',
    `email` string COMMENT '邮箱',
    `user_level` string COMMENT '用户等级',
    `create_time` string COMMENT '创建时间',
    `operate_time` string COMMENT '操作时间',
    `start_date`  string COMMENT '有效开始日期',
    `end_date`  string COMMENT '有效结束日期'
) COMMENT '订单拉链临时表'
stored as parquet
location '/warehouse/gmall/dwd/dwd_dim_user_info_his_tmp/'
tblproperties ("parquet.compression"="lzo");

```

向拉链表导入初始数据（第一天的数据，模拟首次导入）

```sql
insert overwrite TABLE  dwd_dim_user_info_his
select 
    *,'9999-99-99'
FROM ods_user_info
where dt='2020-03-29'
```

之后每一次导入时，都需要把当日新增的数据和历史数据进行合并，合并后先导入到临时表，再导入到原始表。

合并： ① 为新增和变化的数据，添加 startdate=新增和变化的日期，enddate=9999-99-99。

​			② 历史表中发生变化的数据，enddate=当前日期-1。

​			③ 历史表没有发生变化的数据，保持原貌。

```sql
insert overwrite TABLE  dwd_dim_user_info_his_tmp
select 
    old.id,
    old.name, old.birthday, old.gender, old.email, old.user_level, 
    old.create_time, old.operate_time, old.start_date,
    if (`new`.id is not null and old.end_date='9999-99-99',date_sub('2020-03-30',1),old.end_date)
FROM dwd_dim_user_info_his old 
left join
(select 
    *
FROM ods_user_info
where dt='2020-03-30') new
on old.id=new.id
UNION all
select 
    id, name, birthday, gender, email, user_level, create_time, 
    operate_time, '2020-03-30', '9999-99-99'
FROM ods_user_info
where dt='2020-03-30'
```

将临时表数据导入覆盖到原始表

```sql
insert overwrite table dwd_dim_user_info_his select * from dwd_dim_user_info_his_tmp
```



### 4.2.3 DWD 层业务数据事实表

#### 4.2.3.1 事实表如何建模

遵循流程： 选择业务线 ---> 对应的事实表(MySQL或ODS层) ---> 基于 3W 原则，选择这个事实表涉及的维度表 ---> 选择事实表中的度量字段。

DWD 层事实表有以下字段：

① ODS 层事实表的主键。

② 有和维度表进行关联的外键。例如有订单事实表，希望获取订单中的商品详情，那么订单事实表需要有 sku_id 的字段，和商品维度表的 id 进行关联。

③ ODS 层事实表中的度量字段。

DWD 层事实表和 ODS 层事实表的关系：DWD 层事实表会选取 ODS 层事实表的部分字段；DWD 层事实表会比 ODS 层事实表多出部分维度表的外键字段。



#### 4.2.3.2 事实表的分类

**事务型事实表**：指当前描述的事实，一旦写入到表 (mysql) 中，就不会再修改，例如： 支付流水，订单详情，会按天同步每日新增的数据，例如： 2020-03-29 号会同步 3-29 日新生成的所有的支付流水。





**周期型快照事实表**： 指当前描述的事实，首先需要有一个时间的范围，称为周期。快照指的是记录事实在某个时刻的状态。周期型快照即在一段周期范围内，记录某个时刻、事实的状态。例如关心一天的范围内，用户在最后留在购物车中的某件商品的数量，可以采用周期性快照事实表，比如加购表和收藏表。

事务型事实表的特征是数据一旦生成，就不会变化；

周期型快照事实表的特征是表中的某个字段可能发送周期性的变化；

周期型快照事实表希望记录的是事实在一段周期变化后，最后时刻的快照信息。



**累积型事实表**： 指当前描述的事实，可能会在一个业务周期内发生变化，希望记录每次变化的某个度量值，例如业务进度的度量或其他的度量。例如记录订单每个状态变化的时间，前提是 mysql 中事实的相应字段也会发生变化。



同步数据时： 

**事务型事实表** 采取增量同步(同步每天新增的数据)

**周期型快照事实表** 采取全量同步(数据规模小可以全量)

**累积型事实表** 采取同步新增和变化的数据



#### 4.2.3.3 dwd_fact_order_detail

订单详情事实表

选取 ods_order_detail 作为事实表，大部分字段从 ods_order_detail 获取；选取 province_id 作为外键，从 ods_order_info 取，使用 ods_order_info.id = ods_order_detail.orderid 进行关联。选取 total_amount 作为度量。

```sql
INSERT overwrite TABLE dwd_fact_order_detail PARTITION(dt='2020-03-03')
SELECT t1.id, t1.order_id, t1.user_id, t1.sku_id, t1.sku_name, 
t1.order_price, t1.sku_num, t1.create_time, t2.province_id, t2.total_amount
FROM
(SELECT id, order_id, user_id, sku_id, sku_name, 
order_price, sku_num, create_time FROM ods_order_detail where dt='2020-03-03') t1
JOIN
(SELECT id, final_total_amount total_amount, province_id FROM ods_order_info where dt='2020-03-03')t2
ON t1.order_id=t2.id
```



#### 4.2.3.4 dwd_fact_payment_info

支付事实表

选取 ods_payment_info 作为事实表，大部分字段从 ods_payment_info 取；选取 province_id 作为外键，从 ods_order_info 取，使用 ods_order_info.id=ods_payment_info.orderid 进行关联。选择 total_amount 作为度量。

```sql
insert overwrite table dwd_fact_payment_info PARTITION(dt='2020-03-29')
select 
    t1.id, t1.out_trade_no, t1.order_id, t1.user_id,
    t1.alipay_trade_no, t1.total_amount payment_amount, t1.subject,
    t1.payment_type, t1.payment_time,
    t2.province_id
from
(select * from ods_payment_info where dt='2020-03-29') t1
LEFT JOIN
(SELECT id,province_id from ods_order_info where dt='2020-03-29')t2
on t1.order_id=t2.id
```

#### 4.2.3.5 dwd_fact_order_refund_info

退款事实表

① 选取 ods_order_refund_info 作为事实表

② 选取 ods_order_refund_info 的 sku_id 和 user_id 和 order_id 作为维度

③ 选取 refund_num 和 refund_amount 作为度量

```sql
insert overwrite table dwd_fact_order_refund_info PARTITION(dt='2020-03-29')
SELECT id, user_id, order_id, sku_id, refund_type, 
refund_num, refund_amount, refund_reason_type,
create_time
FROM ods_order_refund_info
where dt='2020-03-29'
```

#### 4.2.3.6 dwd_fact_comment_info

评价事实表

① 选取 ods_comment_info 作为评价事实表

② 选取 ods_comment_info 的 user_id、sku_id、create_time 作为维度参考关联字段

③ 选取 appraise（评价类型）作为度量

```sql
insert overwrite table dwd_fact_comment_info PARTITION(dt='2020-03-29')
SELECT id, user_id, sku_id, spu_id, order_id, appraise, 
create_time
FROM ods_comment_info
where dt='2020-03-29'
```

#### 4.2.3.7 dwd_fact_cart_info

周期型快照事实表关心的是一个统计周期（例如一天）结束时，购物车中的状态。由于购物车状态采用的是每日全量同步，每天在0点，将前一天购物车中的状态信息进行同步，而前一天中购物车信息是如何变化的，我们不关心。

ods_cart_info 同步的就是每一天购物车最后状态的数据。

① 选择 ods_cart_info 作为事实表

② 选择 sku_id、user_id、create_time、operate_time、order_time 作为和维度表关联的字段

③ 选择 sku_num 作为度量

```sql
insert overwrite table dwd_fact_cart_info PARTITION(dt='2020-03-29')
SELECT id, user_id, sku_id, cart_price, sku_num, 
sku_name, create_time, operate_time, is_ordered, order_time
FROM gmall.ods_cart_info
where dt='2020-03-29'
```

#### 4.2.3.8 dwd_fact_favor_info

周期型快照事实表，关心的是一个周期（1天），最终时刻收藏夹的状态。

① 选择 ods_favor_info 作为事实表

② 选择 user_id、sku_id、create_time、cancel_time 作为和维度表关联的字段

③ 选择 is_cancel（是否还收藏）作为度量

```sql
insert overwrite table dwd_fact_favor_info PARTITION(dt='2020-03-29')
SELECT id, user_id, sku_id, spu_id, is_cancel, 
create_time, cancel_time
FROM gmall.ods_favor_info
where dt="2020-03-29"
```

#### 4.2.3.9 dwd_fact_coupon_use

我们关心的是领取优惠券这个事实在不同的阶段发生的时间点，因此使用累积型事实表。

① 选择事实表 ods_coupon_use

② 选择 coupon_id、user_id、get_time、using_time、used_time 作为维度

③ 选择时间作为度量

从 ods_coupon_use 单表查询即可，但需注意： dwd_fact_coupon_use 是一个分区表，但是分区字段 dt，并不是要导入数据的日期，而是事实最开始发生的时间，即领取时间 get_time。

原则： 累积型快照事实表，都会选择事实生命周期的最早的时间作为分区的字段。

插入数据的方式： get_time 是哪个时间的数据，就插入到哪个分区目录。

每天同步数据时，如果历史数据发生了变化，需要修改之前的历史数据，将新的数据覆盖历史分区。今天同步的数据，包含了哪个get_time的分区，就覆盖这个分区，即只覆盖变化的分区。步骤如下：

​								今天同步的数据，包含了哪个get_time的分区，就覆盖这个分区！也就是只覆盖变化的分区！

① 查询哪些日期分区的数据需要被覆盖(今天导入的数据中哪些历史日期的数据发生了变化)，从这些日期中查询出旧数据

② 再查询今天导入的数据有哪些新数据

③ 新旧交替

④ 覆盖老数据

##### 4.2.3.9.1 函数介绍 

date_format(日期，样式)：将日期格式化为指定的样式

nvl(值1，默认值)：如果值1为 null，取默认值，否则取值1

##### 4.2.3.9.2 动态分区

insert overwrite table dwd_fact_coupon_use PARTITION(dt='xxxx') ： 是静态分区，在插入数据时，明确指定数据要插入到哪个分区。

insert overwrite table dwd_fact_coupon_use PARTITION(dt): 根据 dt 的字段的值，将不同的值动态插入到不同的分区。

实现动态分区的条件：

① 默认 hive 是不允许动态分区的，需要设置 set hive.exec.dynamic.partition.mode=nonstrict。

② 分区列必须位于查询的最后一个字段。

```sql
insert overwrite table dwd_fact_coupon_use PARTITION(dt)
SELECT
    nvl(new.id,old.id) id,
    nvl(new.coupon_id,old.coupon_id) coupon_id,
    nvl(new.user_id,old.user_id) user_id,
    nvl(new.order_id,old.order_id) order_id,
    nvl(new.coupon_status,old.coupon_status) coupon_status,
    nvl(new.get_time,old.get_time) get_time,
    nvl(new.using_time,old.using_time) ,
    nvl(new.used_time,old.used_time) ,
    date_format(nvl(new.get_time,old.get_time),'yyyy-MM-dd')
FROM
(
   select 
        *
   from dwd_fact_coupon_use
   where dt in
    (select 
        date_format(get_time,'yyyy-MM-dd')
    from ods_coupon_use
    where dt='2020-03-29' and get_time<'2020-03-29')
)old
FULL OUTER JOIN
(
   select 
        *
    from ods_coupon_use
    where dt='2020-03-29' 
)new
on old.id=new.id
```

#### 4.2.3.10 dwd_fact_order_info

dwd_fact_order_info 描述一个订单从开始下单，发货，收货，退货等时间信息。dwd_fact_order_info 是累积型快照事实表，创建思路如下：

① 选取事实表 ods_order_info

② user_id、activity_id、province_id 各种时间作为维度

③ 选取各种时间作为度量

从 ods_order_info 表中选取大部分字段；

从 ods_activity_order 取 activity_id 字段，使用 ods_activity_order.orderid=ods_order_info.id 进行关联；

从 ods_order_status_log 取 payment_time、cancel_time、finish_time、refund_time、refund_finish_time。例如 order-status=1002，代表已经支付，取当前的 operate_time 作为支付时间；dwd_fact_order_info 以事实的最初的开始时间作为分区字段，采取下单时间 create_time 作为分区字段。

实现： ① 取发生变化的旧数据

​			② 取新数据

​			③ 新旧交替

​			④ 覆盖旧数据

##### 4.2.3.10.1 函数介绍

concat(str1,str2,str3,...)：将多个字符串进行拼接，要求字符串必须全部不为 null，一旦有一个为null，结果即为 null。

concat_ws(分隔符，str...|array<string>)：将数组中的字符串和多个字符串使用分隔符进行拼接，忽略 null 值。

collect_set(列名)：将一列多行的N个值，存入一个数组中，去重。

collect_list(列名)：将一列多行的N个值，存入一个数组中，不去重。

str_to_map(转换的字符串, entry的分隔符, k-v之间的分隔符)：返回字符串被分割后的 map。

```sql
insert overwrite table dwd_fact_order_info PARTITION(dt)
select 
    nvl(new.id,old.id),
    nvl(new.order_status,old.order_status),
    nvl(new.user_id,old.user_id),
    nvl(new.out_trade_no,old.out_trade_no),
    nvl(new.create_time,old.create_time),
    nvl(new.timeMap['1002'],old.payment_time),
    nvl(new.timeMap['1003'],old.cancel_time),
    nvl(new.timeMap['1004'],old.finish_time),
    nvl(new.timeMap['1005'],old.refund_time),
    nvl(new.timeMap['1006'],old.refund_finish_time),
    nvl(new.province_id,old.province_id),
    nvl(new.activity_id,old.activity_id),
    nvl(new.original_total_amount,old.original_total_amount),
    nvl(new.benefit_reduce_amount,old.benefit_reduce_amount),
    nvl(new.feight_fee,old.feight_fee),
    nvl(new.final_total_amount,old.final_total_amount),
    date_format(nvl(new.create_time,old.create_time),'yyyy-MM-dd')        
from
(select *
from dwd_fact_order_info
where dt in 
(
   select 
        date_format(create_time,'yyyy-MM-dd')
   from ods_order_info
   where dt='2020-03-29' and create_time<'2020-03-29'
)) old
FULL OUTER JOIN
(SELECT
    t1.*,t2.activity_id,t3.timeMap
from
(select * from ods_order_info where dt='2020-03-29') t1
join
(select order_id,str_to_map(concat_ws(',',collect_set(concat(order_status,'=',operate_time))),',','=') timeMap
from ods_order_status_log where dt='2020-03-29'
group by order_id) t3
on t3.order_id=t1.id
left join
(select order_id,activity_id  from ods_activity_order where dt='2020-03-29') t2
on t1.id=t2.order_id) new
on old.id=new.id
```



## 4.3 DWS 层

### 4.3.1 DWS 层的特征

① 数据由 dwd 层导入。

② 建模上使用宽表（字段很多的表），宽表选择一个主题为核心，将和主题相关的字段从各个表中全部查询插入到宽表。使用宽表的好处是，在查询 DWS 层数据时，不需要多次 JOIN，只需要从宽表中单表查询即可。

③ 统计每天的业务数据和日志数据。

### 4.3.2 业务概念

（1）用户

用户以设备为判断标准，在移动统计中，每个独立设备认为是一个独立用户。Android 系统根据 IMEI 号，IOS 系统根据 OpenUDID 来标识一个独立用户，每部手机一个用户。

（2）新增用户

首次联网使用应用的用户。如果一个用户首次打开某 APP，那这个用户定义为新增用户；卸载再安装的设备，不会被算作一次新增。新增用户包括日新增用户、周新增用户、月新增用户。

（3）活跃用户

打开应用的用户即为活跃用户，不考虑用户的使用情况。每天一台设备打开多次会被计为一个活跃用户。

（4）周（月）活跃用户

某个自然周（月）内启动过应用的用户，该周（月）内的多次启动只记一个活跃用户。

（5）月活跃率

月活跃用户与截止到该月累计的用户总和之间的比例。

（6）沉默用户

用户仅在安装当天（次日）启动一次，后续时间无再启动行为。该指标可以反映新增用户质量和用户与APP的匹配程度。

（7）版本分布

不同版本的周内各天新增用户数，活跃用户数和启动次数。利于判断 APP 各个版本之间的优劣和用户行为习惯。

（8）本周回流用户

上周未启动过应用，本周启动了应用的用户。

（9）连续 n 周活跃用户

连续 n 周，每周至少启动一次。

（10）忠诚用户

连续活跃 5 周以上的用户

（11）连续活跃用户

连续 2 周及以上活跃的用户

（12）近期流失用户

连续 n（2<= n <= 4）周没有启动应用的用户。（第n+1周没有启动过）

（13）留存用户

某段时间内的新增用户，经过一段时间后，仍然使用应用的被认作是留存用户；这部分用户占当时新增用户的比例即是留存率。例如，5月份新增用户200，这200人在6月份启动过应用的有100人，7月份启动过应用的有80人，8月份启动过应用的有50人；则5月份新增用户一个月后的留存率是50%，二个月后的留存率是40%，三个月后的留存率是25%。

（14）用户新鲜度

每天启动应用的新老用户比例，即新增用户数占活跃用户数的比例。

（15）单次使用时长

每次启动使用的时间长度。

（16）日使用时长

累计一天内的使用时间长度。

（17）启动次数计算标准

IOS 平台应用退到后台就算一次独立的启动；Android 平台我们规定，两次启动之间的间隔小于30秒，被计算一次启动。用户在使用过程中，若因收发短信或接电话等退出应用30秒又再次返回应用中，那这两次行为应该是延续而非独立的，所以可以被算作一次使用行为，即一次启动。业内大多使用30秒这个标准，但用户还是可以自定义此时间间隔。

​		

### 4.3.3 常用函数

#### 4.3.3.1 next_day

next_day ('日期','周几')：返回日期之后的第一个周几。周几可以使用完整名称 (Monday)，也可以简写 (MO)。

### 4.3.4 一键造数据脚本

#### 4.3.4.1 分析

① 用户行为日志

​	环境：开启采集通道

​	步骤： a) 将集群的时间调整为所造数据日期中最早的一天

​				b) 启动采集通道

​				c) log.sh 造数据

​				d) dt.sh 修改时间

​				e) 循环步骤 c 和 d

② 业务数据

​	环境： 启动 hadoop

​	步骤： a)  dt.sh 修改时间

​				b) 向 mysql 中插入数据：java -jar xxx.jar 

​					application.properties 重要参数：

​					mock.date = 日期

​					mock.clear = 1

​					1 是重置，0 为不重置。第一次导入必须改为1，之后为0

​				c) 执行 mysql_to_hdfs.sh   first|all  日期

​					第一次导入：第一个参数传入 first；之后导入： 都是 all

③ 向数仓中导入数据：

ODS 层：hdfs_to_ods_db.sh  first|all

​				hdfs_to_ods_log.sh

DWD 层：ods_to_dwd_log.sh

​				ods_to_dwd_db.sh（需要准备）

​				

#### 4.3.4.2 脚本设计

无需传参，日期由用户写在一个文件中，读取文件中的日期，要求日期文件中，每个日期写 1 行；也可以将日期写到循环中，对日期进行遍历。



### 4.3.5 DWS 层行为表

#### 4.3.5.1 dws_uv_detail_daycount

用户日活统计表

活跃用户：  每天启动了应用，即视为活跃；用户为设备。

建表思路：从 dwd_start_log（启动日志表）取数据即可。用户每一次启动应用就在dwd_start_log 生成一条信息。从 dwd_start_log 按照每天的数据，使用 mid_id 进行分组；分组后将同一个设备的多条信息合并，再使用 count(*) 统计启动次数。

```sql
insert overwrite TABLE dws_uv_detail_daycount PARTITION(dt='2020-03-29')
SELECT mid_id, 
       	  concat_ws('|',COLLECT_set(user_id)), 
          concat_ws('|',COLLECT_set(version_code)),
          concat_ws('|',COLLECT_set(version_name)),
          concat_ws('|',COLLECT_set(lang)),
          concat_ws('|',COLLECT_set(source)),
          concat_ws('|',COLLECT_set(os)),
          concat_ws('|',COLLECT_set(area)),
          concat_ws('|',COLLECT_set(model)),
          concat_ws('|',COLLECT_set(brand)),
          concat_ws('|',COLLECT_set(sdk_version)),
          concat_ws('|',COLLECT_set(gmail)),
          concat_ws('|',COLLECT_set(height_width)),
          concat_ws('|',COLLECT_set(app_time)),
          concat_ws('|',COLLECT_set(network)),
          concat_ws('|',COLLECT_set(lng)),
          concat_ws('|',COLLECT_set(lat)),
          count(*)
FROM dwd_start_log
where dt='2020-03-29'
group by mid_id
```



#### 4.3.5.2 dws_user_action_daycount

以用户为主题，统计一个用户每天的行为(下单，支付，评论，退款等)。

建模的原则： 尽量将和此主题相关的所有的信息都进行汇总，通用性和扩展性强，有利于应对日后需求变更；当然一般情况下，要考虑项目进度，按需建模。

```sql
user_id string comment '用户 id',
    login_count bigint comment '登录次数',
    cart_count bigint comment '加入购物车次数',
    cart_amount double comment '加入购物车金额',
    order_count bigint comment '下单次数',
    order_amount    decimal(16,2)  comment '下单金额',
    payment_count   bigint      comment '支付次数',
    payment_amount  decimal(16,2) comment '支付金额'
```

① 所有指标的统计都需要将当天的所有数据按照 user_id 进行分组聚合。

② login_count 从 dwd_start_log 表中找  ， 使用当天的日期和 user_id is not null 进行过滤。

③ cart_count，cart_amount 从 dwd_fact_cart_info(全量表) 中导入。使用当天的日期进行过滤，按照用户分组，通过 count( * ) 统计加购次数，通过 sum(cart_price × sku_num) 统计加入购物车金额。

④ order_count、order_amount 从 dwd_fact_order_info（累积性快照事实表）使用 dt=当天日期 进行过滤，按照user_id 分组，统计 order_count，order_amount；

或使用 dwd_fact_order_detail（事务型快照事实表），令 dt=当天日期 进行过滤，按照 user_id 分组，统计 order_count，order_amount。

⑤ 从 dwd_fact_payment_info 使用 dt=当日日期 进行过滤，按照 user_id 分组，统计 payment_count，payment_amount。

注意： 可能有些人只登录，但是不下单，不支付，不加购，统计时不能将这些人漏掉。

​			如果使用 full join ，不需要注意表的顺序；

​			如果使用 left join ，必须让统计 login_count 的表作为左表。

```sql
with 
t1 as (
select 
    user_id,count(*) login_count
from dwd_start_log 
where dt='2020-03-28' and user_id is not null
group by user_id
),
t2 as (
   select 
        user_id,COUNT(*) cart_count,
        sum(cart_price * sku_num )cart_amount
   from dwd_fact_cart_info
   where dt='2020-03-28' and date_format(create_time,'yyyy-MM-dd')='2020-03-28'
   group by user_id
),
t3 as(
    SELECT
         user_id,COUNT(*) order_count,sum(total_amount) order_amount
    from dwd_fact_order_detail
    where dt='2020-03-28'
    GROUP by user_id
),
t4 as(
    select
    user_id,COUNT(*) payment_count, SUM(payment_amount) payment_amount
    from dwd_fact_payment_info
    where dt='2020-03-28'
    GROUP by user_id
    
)
insert overwrite TABLE dws_user_action_daycount PARTITION(dt='2020-03-28')
SELECT
    t1.user_id,t1.login_count,
    nvl(cart_count,0),
     nvl(cart_amount,0),
      nvl(order_count,0),
       nvl(order_amount,0),
        nvl(payment_count,0),
         nvl(payment_amount,0)
FROM t1 
LEFT JOIN t2 on t1.user_id=t2.user_id
LEFT JOIN t3 on t1.user_id=t3.user_id
LEFT JOIN t4 on t1.user_id=t4.user_id
```

方法二：采用 union all，要求每个 select 子句的字段必须完全一致。

```sql
insert overwrite TABLE dws_user_action_daycount PARTITION(dt='2020-03-28')
select
    user_id,sum(login_count),
    sum(cart_count),
    sum(cart_amount),
    sum(order_count),
    sum(order_amount),
    sum(payment_count),
    sum(payment_amount)
from
(
select 
    user_id,count(*) login_count,0 cart_count,0 cart_amount,
    0 order_count,0 order_amount,0 payment_count,0 payment_amount
from dwd_start_log 
where dt='2020-03-28' and user_id is not null
group by user_id
union all
   select 
         user_id,count(*) login_count,COUNT(*) cart_count,sum(cart_price * sku_num ) cart_amount,
    0 order_count,0 order_amount,0 payment_count,0 payment_amount
   from dwd_fact_cart_info
   where dt='2020-03-28' and date_format(create_time,'yyyy-MM-dd')='2020-03-28'
   group by user_id
union all
    SELECT
     user_id,count(*) login_count,0 cart_count,0 cart_amount,
    COUNT(*) order_count,sum(total_amount) order_amount,0 payment_count,0 payment_amount
    from dwd_fact_order_detail
    where dt='2020-03-28'
    GROUP by user_id
union all
    select
     user_id,count(*) login_count,0 cart_count,0 cart_amount,
    0 order_count,0 order_amount,COUNT(*) payment_count,SUM(payment_amount) payment_amount
    from dwd_fact_payment_info
    where dt='2020-03-28'
    GROUP by user_id
    
) tmp
GROUP by user_id

```

#### 4.3.5.3 dws_sku_action_daycount

以商品为统计的目标，统计一个商品每天被下单，支付，评论等的指标。

```sql
sku_id string comment 'sku_id',
	// 从订单详情表dwd_fact_order_detail 只取当天 dt=xxx
    order_count bigint comment '被下单次数',
    order_num bigint comment '被下单件数',
    order_amount decimal(16,2) comment '被下单金额',
    // 从支付详情表dwd_fact_payment_info，判断商品所下的订单是否被支付了 
    //  取 当天和前一天的订单数据，因此存在跨天支付
    payment_count bigint  comment '被支付次数',
    payment_num bigint comment '被支付件数',
    payment_amount decimal(16,2) comment '支付优惠前金额',
    // 从退款事实表dwd_fact_order_refund_info 取当天 dt=xx
    refund_count bigint  comment '被退款次数',
    refund_num bigint comment '被退款件数',
    refund_amount  decimal(16,2) comment '被退款金额',
    // 加购表取dwd_fact_cart_info 取当天   dt=xxx and create_time=xxx
    cart_count bigint comment '被加入购物车次数',
    cart_num bigint comment '被加入购物车件数',
    // 从收藏表dwd_fact_favor_info取 取当天  dt=xxx and create_time=xxx
    favor_count bigint comment '被收藏次数',
    // 从评价表取dwd_fact_comment_info 取当天  dt=xx 
    appraise_good_count bigint comment '好评数',
    appraise_mid_count bigint comment '中评数',
    appraise_bad_count bigint comment '差评数',
    appraise_default_count bigint comment '默认评价数'

```

从不同的表取商品当日的数据时，使用相应字段来过滤出当日的数据。

目前存在问题：  payment_amount 指我们要统计的商品的支付金额。商品的支付金额在支付表中，而支付表中只有整笔订单的支付金额。而一笔订单可能包含多个商品，因此基于目前表的设计，这个字段不能求。

改进策略：在订单详情表中，生成一个字段，表示商品的实际应支付额。目前只能使用提交订单时商品的的金额代替之。

```SQL
insert overwrite table dws_sku_action_daycount PARTITION(dt='2020-03-28')
SELECT
    sku_id, SUM(order_count),SUM(order_num),
    SUM(order_amount),SUM(payment_count),
    SUM(payment_num),
    SUM(payment_amount),
    SUM(refund_count),
    SUM(refund_num),
    SUM(refund_amount),
    SUM(cart_count),
    SUM(cart_num),
    sum(favor_count),
    sum(appraise_good_count),
    sum(appraise_mid_count),
    sum(appraise_bad_count),
    sum(appraise_default_count)
FROM
(
   SELECT
     sku_id,count(*) order_count,sum(sku_num) order_num,
     sum(total_amount) order_amount,
     0 payment_count, 0 payment_num, 0 payment_amount, 
0 refund_count, 0 refund_num,0 refund_amount, 
0 cart_count,0 cart_num, 
0 favor_count, 
0 appraise_good_count,0 appraise_mid_count, 0 appraise_bad_count,0 appraise_default_count
    from dwd_fact_order_detail
    where dt='2020-03-28'
    GROUP by sku_id
    union all
    SELECT
        sku_id,0 order_count,0 order_num,0 order_amount,
        count(*) payment_count,
        sum(sku_num )payment_num,
        sum(total_amount) payment_amount,
        0 refund_count, 0 refund_num,0 refund_amount, 
0 cart_count,0 cart_num, 
0 favor_count, 
0 appraise_good_count,0 appraise_mid_count, 0 appraise_bad_count,0 appraise_default_count
    from
    (SELECT 
        sku_id,order_id,total_amount,sku_num
    from dwd_fact_order_detail where dt='2020-03-28' or dt=date_sub('2020-03-28',1)) o
    JOIN
    (SELECT 
        order_id
    from dwd_fact_payment_info where dt='2020-03-28') p
    ON o.order_id=p.order_id
    GROUP by sku_id
     union all
      SELECT
     sku_id,0 order_count,0 order_num,0 order_amount,
     0 payment_count, 0 payment_num, 0 payment_amount,
     count(*) refund_count,sum(refund_num) refund_num,
     sum(refund_amount) refund_amount,
     0 cart_count,0 cart_num, 
0 favor_count, 
0 appraise_good_count,0 appraise_mid_count, 0 appraise_bad_count,0 appraise_default_count
    from dwd_fact_order_refund_info
    where dt='2020-03-28'
    GROUP by sku_id
     union all
    SELECT
     sku_id,0 order_count,0 order_num,0 order_amount,
     0 payment_count, 0 payment_num, 0 payment_amount,
      0 refund_count, 0 refund_num,0 refund_amount,
     count(*)  cart_count,sum(sku_num) cart_num,
     0 favor_count, 
0 appraise_good_count,0 appraise_mid_count, 0 appraise_bad_count,0 appraise_default_count
    from dwd_fact_cart_info
    where dt='2020-03-28' and date_format(create_time,'yyyy-MM-dd')='2020-03-28'
    GROUP by sku_id
     union all
     SELECT
     sku_id,0 order_count,0 order_num,0 order_amount,
     0 payment_count, 0 payment_num, 0 payment_amount,
      0 refund_count, 0 refund_num,0 refund_amount,
      0 cart_count,0 cart_num,
     count(*) favor_count,
     0 appraise_good_count,0 appraise_mid_count, 0 appraise_bad_count,0 appraise_default_count
    from dwd_fact_favor_info
    where dt='2020-03-28' and date_format(create_time,'yyyy-MM-dd')='2020-03-28'
    GROUP by sku_id
     union all
SELECT
     sku_id,0 order_count,0 order_num,0 order_amount,
     0 payment_count, 0 payment_num, 0 payment_amount,
      0 refund_count, 0 refund_num,0 refund_amount,
      0 cart_count,0 cart_num,0 favor_count,
     sum(if(appraise='1201',1,0)) appraise_good_count, 
    sum(if(appraise='1202',1,0)) appraise_mid_count, 
    sum(if(appraise='1203',1,0)) appraise_bad_count, 
    sum(if(appraise='1204',1,0)) appraise_default_count
    from dwd_fact_comment_info
    where dt='2020-03-28'
    GROUP by sku_id
)tmp
GROUP by sku_id
```

#### 4.3.5.4 dws_coupon_use_daycount

```sql
// 在dwd_dim_coupon_info表取 取dt=当天
`coupon_id` string  COMMENT '优惠券ID',
    `coupon_name` string COMMENT '购物券名称',
    `coupon_type` string COMMENT '购物券类型 1 现金券 2 折扣券 3 满减券 4 满件打折券',
    `condition_amount` string COMMENT '满额数',
    `condition_num` string COMMENT '满件数',
    `activity_id` string COMMENT '活动编号',
    `benefit_amount` string COMMENT '减金额',
    `benefit_discount` string COMMENT '折扣',
    `create_time` string COMMENT '创建时间',
    `range_type` string COMMENT '范围类型 1、商品 2、品类 3、品牌',
    `spu_id` string COMMENT '商品id',
    `tm_id` string COMMENT '品牌id',
    `category3_id` string COMMENT '品类id',
    `limit_num` string COMMENT '最多领用次数',
    // 从dwd_fact_coupon_use取 dt<=当天(全表扫描)
    // 因此存在之前领取的，今天下单或支付的情形
    `get_count` bigint COMMENT '领用次数',
    `using_count` bigint COMMENT '使用(下单)次数',
    `used_count` bigint COMMENT '使用(支付)次数'

```

```sql
insert overwrite table dws_coupon_use_daycount PARTITION(dt='2020-03-28')
select 
    t1.*,get_count,using_count,used_count
from
(select 
    id, coupon_name, coupon_type, condition_amount, 
condition_num, activity_id, benefit_amount, benefit_discount, 
create_time, range_type, spu_id, tm_id, category3_id, limit_num
from dwd_dim_coupon_info
where dt='2020-03-28') t1
JOIN
(
   select 
        coupon_id,
        sum(IF(dt='2020-03-28',1,0)) get_count,
        sum(IF(date_format(using_time,'yyyy-MM-dd')='2020-03-28',1,0)) using_count,
        sum(IF(date_format(used_time,'yyyy-MM-dd')='2020-03-28',1,0)) used_count
   from dwd_fact_coupon_use
   GROUP by coupon_id
) t2
on t1.id=t2.coupon_id
```

#### 4.3.5.5 dws_activity_info_daycount

```sql
  //从dwd_dim_activity_info取  取dt=当前日期
  `id` string COMMENT '编号',
    `activity_name` string  COMMENT '活动名称',
    `activity_type` string  COMMENT '活动类型',
    `start_time` string  COMMENT '开始时间',
    `end_time` string  COMMENT '结束时间',
    `create_time` string  COMMENT '创建时间',
    //从dwd_fact_order_info取下单信息，
    // 订单支付存在跨天的情况 取当天和前一天下单 
    `order_count` bigint COMMENT '下单次数',
    `payment_count` bigint COMMENT '支付次数'
```

```sql
insert overwrite table dws_activity_info_daycount PARTITION(dt='2020-03-28')
select
    t1.*,order_count, payment_count
FROM
(SELECT
id, activity_name, activity_type,
start_time, end_time, create_time
FROM dwd_dim_activity_info
where dt='2020-03-28'
group by id, activity_name, activity_type,
start_time, end_time, create_time)  t1
JOIN
(
  SELECT
    activity_id,
    sum(if(dt='2020-03-28',1,0)) order_count,
    sum(if(date_format(payment_time,'yyyy-MM-dd')='2020-03-28',1,0)) payment_count
  FROM dwd_fact_order_info
  where dt='2020-03-28' or dt=date_sub('2020-03-28',1)
  group by activity_id
) t2
on t1.id=t2.activity_id
```

#### 4.3.5.6 dws_sale_detail_daycount

以用户购买行为作为统计的对象。

```sql
//从dwd_dim_user_info_his取最新的用户信息 where end_date='9999-99-99'
user_id   string  comment '用户 id',
    sku_id    string comment '商品 id',
    user_gender  string comment '用户性别',
    //floor(datediff(当前日期,birthday) / 365 ) 或 floor(month_between(当前，birthday) /12)
    user_age string  comment '用户年龄',
    user_level string comment '用户等级',
    
    // 从dwd_dim_sku_info， 取dt=当天
    order_price decimal(10,2) comment '商品价格',
    sku_name string   comment '商品名称',
    sku_tm_id string   comment '品牌id',
    sku_category3_id string comment '商品三级品类id',
    sku_category2_id string comment '商品二级品类id',
    sku_category1_id string comment '商品一级品类id',
    sku_category3_name string comment '商品三级品类名称',
    sku_category2_name string comment '商品二级品类名称',
    sku_category1_name string comment '商品一级品类名称',
    spu_id  string comment '商品 spu',
    
    // 从dwd_fact_order_detail，取dt=当天 
    sku_num  int comment '购买个数',
    order_count bigint comment '当日下单单数',
    order_amount decimal(16,2) comment '当日下单金额'

```

使用 user_id 和 sku_id 进行分组，统计每个人买每件商品的信息。

```sql
insert overwrite TABLE dws_sale_detail_daycount PARTITION(dt='2020-03-28')
select
    t1.user_id,t3.sku_id, t1.user_gender, t1.user_age, t1.user_level,
t3.order_price, t3.sku_name, t3.sku_tm_id,
t3.sku_category3_id, t3.sku_category2_id, t3.sku_category1_id,
t3.sku_category3_name, t3.sku_category2_name, t3.sku_category1_name, 
t3.spu_id,t2.total_sku_num,t2.order_count ,t2.order_amount 
FROM
(select 
    id user_id,gender user_gender,
    FLOOR(datediff('2020-03-28',birthday)/365) user_age, user_level
FROM dwd_dim_user_info_his
WHERE end_date='9999-99-99') t1
JOIN
(
    SELECT
        user_id,sku_id,
        sum(sku_num) total_sku_num,
        sum(total_amount) order_amount,
        count(*) order_count
    FROM dwd_fact_order_detail
    where dt='2020-03-28'
    group by user_id,sku_id
)t2
on t1.user_id=t2.user_id
JOIN
(
    select 
        id sku_id,
        price order_price,
        sku_name, 
        tm_id sku_tm_id,
        category3_id sku_category3_id, 
        category2_id sku_category2_id, 
        category1_id sku_category1_id,
        category3_name sku_category3_name, 
        category2_name sku_category2_name, 
        category1_name sku_category1_name, 
        spu_id
    FROM dwd_dim_sku_info
    where dt='2020-03-28'
)t3 on t2.sku_id=t3.sku_id

```

## 4.4 DWT 层

### 4.4.1 DWT 层数据特征

DWT：以主题为核心，将和此主题相关的所有数据汇总到一张宽表中。

​			DWT 的数据来源于 DWS 层（DWS 层是以某个主题为核心，按照天对数据聚合）。

​			DWT 层的数据，是一张累积型全量表(不是分区表)，统计了这个主题从起始到目前所有的指标。

建模：宽表

累积型全量表的更新： 取历史数据和今天的最新数据，新旧交替，覆盖原表。

DWT 层一般情况都是从对应的 DWS 层单表查询，查询时选取的时间范围应该为所有的数据的范围。

### 4.4.2 dwt_uv_topic

从 dws_uv_detail_daycount 表取数据。

```sql
// 从dws_uv_detail_daycount取
`mid_id` string COMMENT '设备唯一标识',
    `user_id` string COMMENT '用户标识',
    `version_code` string COMMENT '程序版本号',
    `version_name` string COMMENT '程序版本名',
    `lang` string COMMENT '系统语言',
    `source` string COMMENT '渠道号',
    `os` string COMMENT '安卓系统版本',
    `area` string COMMENT '区域',
    `model` string COMMENT '手机型号',
    `brand` string COMMENT '手机品牌',
    `sdk_version` string COMMENT 'sdkVersion',
    `gmail` string COMMENT 'gmail',
    `height_width` string COMMENT '屏幕宽高',
    `app_time` string COMMENT '客户端日志产生时的时间',
    `network` string COMMENT '网络模式',
    `lng` string COMMENT '经度',
    `lat` string COMMENT '纬度',
 // 以下四个指标，从login_count(设备当日活跃次数)取
 // 老用户使用自己的时间，今天的新用户用当天时间
    `login_date_first` string  comment '首次活跃时间',
    //在新的数据中没有记录(今天没登陆的老用户)使用自己的末次活跃时间，否则就用当天
    `login_date_last` string  comment '末次活跃时间',
    //今天没登陆的老用户的活跃次数为0，今天登录的用户活跃次数为login_count
    `login_day_count` bigint comment '当日活跃次数',
    //今天没登陆的老用户的活跃天数为之前的天数，今天登录的新用户的登录天数为1，今天登录的老用户的活跃天数为 之前的天数+1
    或
    在old表的登录天数+在new 表的登录天数
    `login_count` bigint comment '累积活跃天数'

```

插入模式：old full join new on old.id=new.id

![image-20200410144450515](C:\Users\Jeffery\AppData\Roaming\Typora\typora-user-images\image-20200410144450515.png)

判断是今天未登录的老用户：new.id is null

判断是今天登录的老用户：old.id is not null and new.id is not null

判断是今天登录的新用户：old.id is null 

```sql
insert overwrite table dwt_uv_topic
SELECT
    nvl(new.mid_id,old.mid_id),
    concat_ws('|',old.user_id,new.user_id),
    concat_ws('|',old.version_code,new.version_code),
    concat_ws('|',old.version_name,new.version_name),
    concat_ws('|',old.lang,new.lang),
    concat_ws('|',old.source,new.source),
    concat_ws('|',old.os,new.os),
    concat_ws('|',old.area,new.area),
    concat_ws('|',old.model,new.model),
    concat_ws('|',old.brand,new.brand),
    concat_ws('|',old.sdk_version,new.sdk_version),
    concat_ws('|',old.gmail,new.gmail),
    concat_ws('|',old.height_width,new.height_width),
    concat_ws('|',old.app_time,new.app_time),
    concat_ws('|',old.network,new.network),
    concat_ws('|',old.lng,new.lng),
    concat_ws('|',old.lat,new.lat),
    if(old.mid_id is null,'2020-03-28',old.login_date_first) login_date_first,
    if(new.mid_id is  null,old.login_date_last,'2020-03-28') login_date_last,
    nvl(new.login_count,0) login_day_count, 
    nvl(old.login_count,0)+IF(new.login_count is not null,1,0) 
FROM
dwt_uv_topic old 
FULL JOIN
(SELECT *
FROM dws_uv_detail_daycount
where dt='2020-03-28')new
on old.mid_id=new.mid_id
```



### 4.4.3 dwt_user_topic

```sql
user_id string  comment '用户id',
	//old+new（今天）
    login_date_first string  comment '首次登录时间',
    order_date_first string  comment '首次下单时间',
     payment_date_first string  comment '首次支付时间',
    login_date_last string  comment '末次登录时间',
    order_date_last string  comment '末次下单时间',
    payment_date_last string  comment '末次支付时间',
    
    // old+new（今天）
    login_count bigint comment '累积登录天数',
     order_count bigint comment '累积下单次数',
      order_amount decimal(16,2) comment '累积下单金额',
      payment_count decimal(16,2) comment '累积支付次数',
    payment_amount decimal(16,2) comment '累积支付金额',
    
    //取今天之前30天所有的数据进行统计
    login_last_30d_count bigint comment '最近30日登录天数',
    order_last_30d_count bigint comment '最近30日下单次数',
    order_last_30d_amount bigint comment '最近30日下单金额',
    payment_last_30d_count decimal(16,2) comment '最近30日支付次数',
    payment_last_30d_amount decimal(16,2) comment '最近30日支付金额'

```

```sql
insert overwrite table dwt_user_topic
select
    t1.user_id,
    login_date_first,
    login_date_last,
    login_count,
    login_last_30d_count,
    order_date_first,
    order_date_last,
    order_count,
    order_amount,
    order_last_30d_count,
    order_last_30d_amount,
    payment_date_first,
    payment_date_last,
    payment_count,
    payment_amount,
    payment_last_30d_count,
    payment_last_30d_amount
from
    (select
         nvl(old.user_id, new.user_id) user_id,
         if(old.user_id is null, '2020-04-20', old.login_date_first) login_date_first,
         if(old.order_date_first is null, if(new.order_count>0, '2020-04-20', old.order_date_first), old.order_date_first) order_date_first,
         if(old.payment_date_first is null, if(new.payment_count>0, '2020-04-20', old.payment_date_first), old.payment_date_first) payment_date_first,
         if(new.user_id is null, old.login_date_last, '2020-04-20') login_date_last,
         if(new.order_count>0,'2020-04-20',old.order_date_last) order_date_last,
         if(new.payment_count>0,'2020-04-20',old.payment_date_last) payment_date_last,
         (nvl(old.login_count, 0)+if(new.login_count is null, 0, 1)) login_count,
         (nvl(old.login_count, 0)+nvl(new.order_count, 0)) order_count,
         (nvl(old.order_amount, 0)+nvl(new.order_amount, 0)) order_amount,
         (nvl(old.payment_count, 0)+nvl(new.payment_count, 0)) payment_count,
         (nvl(old.payment_amount, 0)+nvl(new.payment_amount, 0)) payment_amount
     from dwt_user_topic old
              full join
          (select * from
              dws_user_action_daycount
           where dt='2020-04-20') new
          on old.user_id=new.user_id) t1
        join
    (select
         user_id,
         sum(`if`(login_count>0, 1, 0)) login_last_30d_count,
         sum(nvl(order_amount, 0)) order_last_30d_amount,
         sum(nvl(order_count, 0)) order_last_30d_count,
         sum(nvl(payment_count, 0)) payment_last_30d_count,
         sum(nvl(payment_amount, 0)) payment_last_30d_amount
     from dws_user_action_daycount
     where dt>=date_sub('2020-04-20', 29)
     group by user_id) t2
    on t1.user_id=t2.user_id;
```

### 4.4.4 dwt_sku_topic

```sql
 sku_id string comment 'sku_id',
    spu_id string comment 'spu_id',
    // 需要dt >= 30天前的日期，需要进行sum()
    order_last_30d_count bigint comment '最近30日被下单次数',
    order_last_30d_num bigint comment '最近30日被下单件数',
    order_last_30d_amount decimal(16,2)  comment '最近30日被下单金额',
   refund_last_30d_count bigint comment '最近三十日退款次数',
    refund_last_30d_num bigint comment '最近三十日退款件数',
    refund_last_30d_amount decimal(10,2) comment '最近三十日退款金额',
    payment_last_30d_count   bigint  comment '最近30日被支付次数',
    payment_last_30d_num bigint comment '最近30日被支付件数',
    payment_last_30d_amount  decimal(16,2) comment '最近30日被支付金额',
    cart_last_30d_count bigint comment '最近30日被加入购物车次数',
    cart_last_30d_num bigint comment '最近30日被加入购物车件数',
     favor_last_30d_count bigint comment '最近30日被收藏次数',
    appraise_last_30d_good_count bigint comment '最近30日好评数',
    appraise_last_30d_mid_count bigint comment '最近30日中评数',
    appraise_last_30d_bad_count bigint comment '最近30日差评数',
    appraise_last_30d_default_count bigint comment '最近30日默认评价数',
    
    // old+new
     order_count bigint comment '累积被下单次数',
    order_num bigint comment '累积被下单件数',
    order_amount decimal(16,2) comment '累积被下单金额',
    payment_count   bigint  comment '累积被支付次数',
    payment_num bigint comment '累积被支付件数',
    payment_amount  decimal(16,2) comment '累积被支付金额',
    refund_count bigint comment '累积退款次数',
    refund_num bigint comment '累积退款件数',
    refund_amount decimal(10,2) comment '累积退款金额',
    cart_count bigint comment '累积被加入购物车次数',
    cart_num bigint comment '累积被加入购物车件数',
    favor_count bigint comment '累积被收藏次数',
    appraise_good_count bigint comment '累积好评数',
    appraise_mid_count bigint comment '累积中评数',
    appraise_bad_count bigint comment '累积差评数',
    appraise_default_count bigint comment '累积默认评价数'

```

```sql
insert overwrite table dwt_sku_topic
SELECT t1.sku_id, spu_id, order_last_30d_count, order_last_30d_num, 
order_last_30d_amount, order_count, order_num, order_amount,
payment_last_30d_count, payment_last_30d_num, payment_last_30d_amount,
payment_count, payment_num, payment_amount, refund_last_30d_count,
refund_last_30d_num, refund_last_30d_amount, refund_count,
refund_num, refund_amount, cart_last_30d_count, cart_last_30d_num, 
cart_count, cart_num, favor_last_30d_count, favor_count, 
appraise_last_30d_good_count, appraise_last_30d_mid_count,
appraise_last_30d_bad_count, appraise_last_30d_default_count,
appraise_good_count, appraise_mid_count, appraise_bad_count,
appraise_default_count
from
(select 
    nvl(old.sku_id,new.sku_id) sku_id,
     nvl(old.order_count,0)+IF(new.order_count is not null,new.order_count,0)  order_count  ,
    nvl(old.order_num,0)+IF(new.order_num is not null,new.order_num,0)  order_num ,
    nvl(old.order_amount,0)+IF(new.order_amount is not null,new.order_amount,0)  order_amount ,
    nvl(old.payment_count,0)+IF(new.payment_count is not null,new.payment_count,0)  payment_count  ,
     nvl(old.payment_num,0)+IF(new.payment_num is not null,new.payment_num,0) payment_num ,
     nvl(old.payment_amount,0)+IF(new.payment_amount is not null,new.payment_amount,0) payment_amount  ,
     nvl(old.refund_count,0)+IF(new.refund_count is not null,new.refund_count,0) refund_count ,
     nvl(old.refund_num,0)+IF(new.refund_num is not null,new.refund_num,0) refund_num ,
     nvl(old.refund_amount,0)+IF(new.refund_amount is not null,new.refund_amount,0) refund_amount ,
     nvl(old.cart_count,0)+IF(new.cart_count is not null,new.cart_count,0) cart_count ,
     nvl(old.cart_num,0)+IF(new.cart_num is not null,new.cart_num,0) cart_num ,
     nvl(old.favor_count,0)+IF(new.favor_count is not null,new.favor_count,0) favor_count ,
    nvl(old.appraise_good_count,0)+IF(new.appraise_good_count is not null,new.appraise_good_count,0)  appraise_good_count ,
     nvl(old.appraise_mid_count,0)+IF(new.appraise_mid_count is not null,new.appraise_mid_count,0) appraise_mid_count ,
     nvl(old.appraise_bad_count,0)+IF(new.appraise_bad_count is not null,new.appraise_bad_count,0) appraise_bad_count ,
     nvl(old.appraise_default_count,0)+IF(new.appraise_default_count is not null,new.appraise_default_count,0) appraise_default_count 
from   
dwt_sku_topic OLD
full join
(select * from dws_sku_action_daycount where dt='2020-03-28') new
on old.sku_id=new.sku_id) t1
left join
(select 
    sku_id,
    sum(order_count) order_last_30d_count ,
    sum(order_num) order_last_30d_num ,
    sum(order_amount) order_last_30d_amount ,
    sum(refund_count) refund_last_30d_count ,
    sum(refund_num) refund_last_30d_num ,
    sum( refund_amount) refund_last_30d_amount ,
    sum(payment_count) payment_last_30d_count  ,
    sum( payment_num) payment_last_30d_num ,
    sum(payment_amount) payment_last_30d_amount  ,
    sum(cart_count) cart_last_30d_count ,
    sum(cart_num) cart_last_30d_num ,
    sum(favor_count)  favor_last_30d_count ,
    sum(appraise_good_count) appraise_last_30d_good_count ,
    sum(appraise_mid_count) appraise_last_30d_mid_count ,
    sum(appraise_bad_count) appraise_last_30d_bad_count ,
    sum(appraise_default_count) appraise_last_30d_default_count 
 from dws_sku_action_daycount
 where dt>=date_sub('2020-03-28',29)
 GROUP by sku_id ) t2
 on t1.sku_id=t2.sku_id
 join
 (select id,spu_id from dwd_dim_sku_info where dt='2020-03-28') t3
 on t1.sku_id=t3.id
```



### 4.4.5 dwt_coupon_topic

```sql
//old+new
`coupon_id` string  COMMENT '优惠券ID',
    `get_day_count` bigint COMMENT '当日领用次数',
    `using_day_count` bigint COMMENT '当日使用(下单)次数',
    `used_day_count` bigint COMMENT '当日使用(支付)次数',
    `get_count` bigint COMMENT '累积领用次数',
    `using_count` bigint COMMENT '累积使用(下单)次数',
    `used_count` bigint COMMENT '累积使用(支付)次数'
```

```sql
insert overwrite table dwt_coupon_topic
SELECT
    nvl(old.coupon_id,new.coupon_id),
    if(new.coupon_id is null,0,new.get_count) get_day_count,
    if(new.coupon_id is null,0,new.using_count) using_day_count,
    if(new.coupon_id is null,0,new.used_count) used_day_count,
    nvl(old.get_count,0)+IF(new.get_count is not null,new.get_count,0) get_count,
    nvl(old.using_count,0)+IF(new.using_count is not null,new.using_count,0) using_count,
    nvl(old.used_count,0)+IF(new.used_count is not null,new.used_count,0) used_count
FROM    
dwt_coupon_topic old
full JOIN
(select * from dws_coupon_use_daycount WHERE dt='2020-03-28')new
on old.coupon_id=new.coupon_id
```

### 4.4.6 dwt_activity_topic

```
//old+new
`id` string COMMENT '活动id',
    `activity_name` string  COMMENT '活动名称',
    `order_day_count` bigint COMMENT '当日日下单次数',
    `payment_day_count` bigint COMMENT '当日支付次数',
    `order_count` bigint COMMENT '累积下单次数',
    `payment_count` bigint COMMENT '累积支付次数'

```

```sql
insert overwrite TABLE gmall.dwt_activity_topic
SELECT 
    nvl(old.id,new.id),
    nvl(new.activity_name,old.activity_name),
    if(new.id is null,0,new.order_count),
    if(new.id is null,0,new.payment_count),
    nvl(old.order_count,0)+IF(new.order_count is not null,new.order_count,0),
    nvl(old.payment_count,0)+IF(new.payment_count is not null,new.payment_count,0)    
FROM
dwt_activity_topic old
full join
(select * from dws_activity_info_daycount where dt='2020-03-28') new 
on old.id=new.id
```



## 4.5 ADS层

### 4.5.1 ADS层数据特征

ADS 紧紧贴合需求，承上 (DWT 主题宽表) 启下 (业务需求)。

ADS 一般情况下是一整张表，里面直接设置了需求所需要的字段，因此涵盖了许多业务术语。

ADS 层数据从 DWT 主题宽表中取。

更新时，每天统计每日的业务数据，插入到 ADS 表中，不是覆盖（每天的统计结果在 ADS 表中只占1行）。

### 4.5.2 设备主题

#### 4.5.2.1 ads_uv_count

活跃设备数（日、周、月）。统计每日的活跃设备，每周的活跃设备，每月的活跃设备

```sql
`dt` string COMMENT '统计日期',
    `day_count` bigint COMMENT '当日用户数量',
    //取一周的每日数据，聚合
    `wk_count`  bigint COMMENT '当周用户数量',
    //取一月的每日数据，聚合
    `mn_count`  bigint COMMENT '当月用户数量',
    // 计算当日所在的周日，看当日是否和周日相等
    // 取当前日期所在的周日： date_sub(next_day('2020-04-07','mo'),1)
    `is_weekend` string COMMENT 'Y,N是否是周末,用于得到本周最终结果',
    
    // last_day('2020-03-28') 是否和传入的日期相等
    `is_monthend` string COMMENT 'Y,N是否是月末,用于得到本月最终结果' 

//如何取本周周一： date_sub(next_day('2020-04-07','mo'),7)
```

```sql
-- 单条数据表 join 不必担心笛卡尔积，但是需要关闭 hive 的严格模式
set hive.strict.checks.cartesian.product=false;
select 
    '2020-03-28',
    day_count,is_weekend,is_monthend,wk_count,mn_count
from
(SELECT 
    count(*) day_count, 
    if( date_sub(next_day('2020-03-28','mo'),1)='2020-03-28','Y','N') is_weekend, 
    if(last_day('2020-03-28')='2020-03-28','Y','N') is_monthend
FROM dwt_uv_topic
WHERE login_date_last='2020-03-28') t1
join
(select 
      count(*)  wk_count 
from dwt_uv_topic
where login_date_last>=date_sub(next_day('2020-03-28','mo'),7)) t2
join
(select 
    count(*) mn_count
from dwt_uv_topic
where date_format(login_date_last,'yyyy-MM')=date_format('2020-03-28','yyyy-MM')) t3
```

#### 4.5.2.2 ads_new_mid_count

每日新增设备。设备以 mid_id 作为字段，统计每天当天新增了哪些设备。

新增： 首次登录时间为统计当天。

```sql
insert into table ads_new_mid_count
select 
    '2020-03-28',count(*)
FROM dwt_uv_topic
where login_date_first='2020-03-28'
```

#### 4.5.2.3 ads_silent_count

沉默用户数。沉默用户：只在安装当天启动过，且启动时间是在7天前。

```sql
insert INTO table ads_silent_count
select 
    '2020-03-28',
    count(*)
FROM dwt_uv_topic
WHERE login_date_first=login_date_last
and login_date_last<date_sub('2020-03-28',7)
```

#### 4.5.2.4 ads_back_count

本周回流用户：上周未活跃，本周活跃的老设备，即不是本周新增设备。

本周回流用户：本周活跃设备  -  本周新增用户  -  上周活跃用户

本周活跃用户 :  最后一次登录时间在本周的周一和周日之间

本周的新增用户:  首次登录时间为本周一之后

上周活跃的用户:  从 dws_uv_detail_daycount 取 dt 为上周的数据

两个结果集取差集：   A left join B where B.xx is null

```sql
SELECT
    '2020-04-15',
    concat(date_sub(next_day('2020-04-15','MO'),7),'_',date_sub(next_day('2020-04-15','MO'),1)),
    count(*)
from
(select 
    current_wk_old.mid_id
from
(select 
    mid_id
from dwt_uv_topic
where (login_date_last 
        BETWEEN  date_sub(next_day('2020-04-15','MO'),7)
        AND  date_sub(next_day('2020-04-15','MO'),1) )
        and
        login_date_first< date_sub(next_day('2020-04-15','MO'),7)) current_wk_old
left join     
(select 
    mid_id
from dws_uv_detail_daycount 
where dt BETWEEN date_sub(next_day('2020-04-15','MO'),14)
         AND date_sub(next_day('2020-04-15','MO'),8) 
GROUP by mid_id) last_wk
on current_wk_old.mid_id=last_wk.mid_id
where last_wk.mid_id is null) tmp
```

#### 4.5.2.5 ads_wastage_count

流失用户：连续7天未活跃的设备

连续7天未活跃： 最后一次登录的时间距离当天日期已经过了至少7天

```sql
insert into table ads_wastage_count
SELECT
    '2020-03-28',count(*)
FROM dwt_uv_topic
where login_date_last<date_sub('2020-03-28',7)
```

#### 4.5.2.6 ads_user_retention_day_rate

留存率：xxx 日期 n 天之后的留存人数  / xxx 日期当日新增人数=留存率

规律：  新增日期 + n日留存 =  日活日期

例如： 统计 2020-03-28 这批新增用户，在3日后的留存率。

​			① 求2020-03-28日新增了多少人，假设为x

​			② 统计 2020-03-28 + 3 = 2020-03-31 日期的这一批新增用户中的活跃人数，假设为y

​			③ y/ x 即为留存率

​		当日留存人数：login_first_date = 新增当天 and login_last_date=活跃当天，符合条件记1人

​		当日新增人数： login_first_date = 新增当天，符合条件记1人

```sql
统计的数据日期   统计的数据的新增日期   留存天数
2020-03-31  2020-03-30          1
2020-03-31  2020-03-29          2
2020-03-31  2020-03-28          3

2020-04-01  2020-03-31          1
2020-04-01  2020-03-30          2
2020-04-01  2020-03-29          3

2020-04-02  2020-04-01          1
2020-04-02  2020-03-31          2
2020-04-02  2020-03-30          3
```

```sql
insert INTO TABLE ads_user_retention_day_rate
select 
    '2020-03-31' stat_date,
    date_sub('2020-03-31',1) create_date,
    1 retention_day,
    sum(if(login_date_first=date_sub('2020-03-31',1) and login_date_last='2020-03-31',1,0)) retention_count,
    sum(if(login_date_first=date_sub('2020-03-31',1),1,0)) new_mid_count,
    cast(nvl(sum(if(login_date_first=date_sub('2020-03-31',1) and login_date_last='2020-03-31',1,0))/sum(if(login_date_first=date_sub('2020-03-31',1),1,0))*100,0) as decimal(10,2)) retention_ratio
FROM dwt_uv_topic
union all
select 
    '2020-03-31' stat_date,
    date_sub('2020-03-31',2) create_date,
    2 retention_day,
    sum(if(login_date_first=date_sub('2020-03-31',2) and login_date_last='2020-03-31',1,0)) retention_count,
    sum(if(login_date_first=date_sub('2020-03-31',2),1,0)) new_mid_count,
    cast (nvl(sum(if(login_date_first=date_sub('2020-03-31',2) and login_date_last='2020-03-31',1,0))/sum(if(login_date_first=date_sub('2020-03-31',2),1,0))*100,0) as decimal(10,2)) retention_ratio
FROM dwt_uv_topic
union all
select 
    '2020-03-31' stat_date,
    date_sub('2020-03-31',3) create_date,
    3 retention_day,
    sum(if(login_date_first=date_sub('2020-03-31',3) and login_date_last='2020-03-31',1,0)) retention_count,
    sum(if(login_date_first=date_sub('2020-03-31',3),1,0)) new_mid_count,
    cast (nvl(sum(if(login_date_first=date_sub('2020-03-31',3) and login_date_last='2020-03-31',1,0))/sum(if(login_date_first=date_sub('2020-03-31',3),1,0))*100,0) as decimal(10,2) )retention_ratio
FROM dwt_uv_topic

```

#### 4.5.2.7 ads_continuity_wk_count

最近连续三周活跃用户数

连续三周活跃：本周活跃，上周活跃，上上周也活跃

本周不管活跃几天，都算是本周的活跃用户

思路： 分别取当日日期前三周(包含本周)的每周的周活设备数据，在每周的统计范围内，对 mid_id 进程去重。将三周的结果拼接后，再按照 mid_id 分组，统计组内数据是3条的 mid_id 的数量。

```sql
insert into TABLE ads_continuity_wk_count
select
    '2020-04-15',
    concat(date_sub(next_day('2020-04-15','MO'),21),'_',date_sub(next_day('2020-04-15','MO'),1)), 
    count(*)
from
(select 
    mid_id
from
(SELECT
    mid_id
from dws_uv_detail_daycount
where dt>=date_sub(next_day('2020-04-15','MO'),7)
GROUP by mid_id
union all
SELECT
    mid_id
from dws_uv_detail_daycount
where dt BETWEEN date_sub(next_day('2020-04-15','MO'),14)
        AND date_sub(next_day('2020-04-15','MO'),8)
GROUP by mid_id
union all
SELECT
    mid_id
from dws_uv_detail_daycount
where dt BETWEEN date_sub(next_day('2020-04-15','MO'),21)
        AND date_sub(next_day('2020-04-15','MO'),15)
GROUP by mid_id) tmp
GROUP by mid_id
having count(*)=3 ) tmp2

```

#### 4.5.2.8 ads_continuity_uv_count

最近七天内连续三天活跃用户数，使用最近七天作为过滤条件。

最近七天内连续三天活跃判断思路：假设有A列，以X递增，以a开头；B列以b开头，以Y递增。如果A列和B列都是连续递增，有

| A    | B    | 连续两列的差值 |
| ---- | ---- | -------------- |
| a    | b    | b-a            |
| a+X  | b+Y  | b-a + (Y-X)    |
| a+2X | b+2Y | b-a + 2(Y-X)   |

即连续两行差值之间，总以Y-X递增。如果Y=X，连续两行的差值之间，总以0递增，差值相同。

| 日期       | 参照列 row_number() | 差值       |
| ---------- | ------------------- | ---------- |
| 2020-03-28 | 1                   | 2020-03-27 |
| 2020-03-29 | 2                   | 2020-03-27 |
| 2020-03-31 | 3                   | 2020-03-28 |

差值相同的则连续，类似于加减消元法思路。现在将差值进行分组，如果组内记录的数量超过3，那么就判定为3天连续。

```sql
insert INTO TABLE ads_continuity_uv_count
select 
    '2020-04-14',
    concat(date_sub('2020-04-14',6),'_','2020-04-14'),
    COUNT(DISTINCT mid_id)
from
(SELECT
     mid_id
from
(select 
    mid_id,dt,
    ROW_NUMBER() over(PARTITION by mid_id order by dt ) rn,
    date_sub(dt,ROW_NUMBER() over(PARTITION by mid_id order by dt )) diffnum
from dws_uv_detail_daycount
where dt>=date_sub('2020-04-14',6)) t1
GROUP by mid_id,diffnum
having count(*)>=3) t2
```

### 4.5.3 会员主题

#### 4.5.3.1 ads_user_topic

会员主题信息。

```sql
dt` string COMMENT '统计日期',
    `day_users` string COMMENT '活跃会员数',
    `day_new_users` string COMMENT '新增会员数',
    `day_new_payment_users` string COMMENT '新增消费会员数',
    `payment_users` string COMMENT '总付费会员数',
    `users` string COMMENT '总会员数',
    // 今天的活跃会员数 /  总会员数
    `day_users2users` decimal(10,2) COMMENT '会员活跃率',
    // 总付费会员数 / 总会员数
    `payment_users2users` decimal(10,2) COMMENT '会员付费率',
    // 新增会员数 / 活跃会员数
    `day_new_users2users` decimal(10,2) COMMENT '会员新鲜度'

```

```sql
insert into TABLE ads_user_topic
select 
    '2020-04-14',
    sum(IF( login_date_last = '2020-04-14',1,0)) day_users,
    sum(IF( login_date_first = '2020-04-14',1,0)) day_new_users,
    sum(IF( payment_date_first = '2020-04-14',1,0)) day_new_payment_users,
    sum(if(payment_count>0,1,0)) payment_users,
    count(*) users,
   cast(sum(IF( login_date_last = '2020-04-14',1,0))/count(*)*100 as decimal(10,2)) day_users2users,
   cast(sum(if(payment_count>0,1,0))/count(*)*100 as decimal(10,2)) payment_users2users,
   cast( sum(IF( login_date_first = '2020-04-14',1,0)) / sum(IF( login_date_last = '2020-04-14',1,0)) * 100 as decimal(10,2)) 
from dwt_user_topic
```

#### 4.5.3.2 ads_user_action_convert_day

漏斗分析（转化率）

```sql
`dt` string COMMENT '统计日期',
	
    // 从dws层取
    `total_visitor_m_count`  bigint COMMENT '总访问人数',
    `cart_u_count` bigint COMMENT '加入购物车的人数',
    `order_u_count` bigint     COMMENT '下单人数',
    `payment_u_count` bigint     COMMENT '支付人数',
    
    `visitor2cart_convert_ratio` decimal(10,2) COMMENT '访问到加入购物车转化率',
    `cart2order_convert_ratio`  decimal(10,2) COMMENT '加入购物车到下单转化率',
    `order2payment_convert_ratio` decimal(10,2) COMMENT '下单到支付的转化率'
```

```sql
 insert into TABLE ads_user_action_convert_day
    select 
        '2020-04-14',
        count(*) total_visitor_m_count,
        sum(if(cart_count>0,1,0)) cart_u_count,
        cast (sum(if(cart_count>0,1,0)) / count(*) * 100 as decimal(10,2)) visitor2cart_convert_ratio,
        sum(if(order_count>0,1,0)) order_u_count,
        cast (sum(if(order_count>0,1,0)) / sum(if(cart_count>0,1,0)) * 100 as decimal(10,2)) cart2order_convert_ratio,
        sum(if(payment_count>0,1,0)) payment_u_count,
        cast ( sum(if(payment_count>0,1,0)) / sum(if(order_count>0,1,0) * 100) as decimal(10,2)) order2payment_convert_ratio
    from dws_user_action_daycount 
    where dt='2020-04-14'
```

### 4.5.4 商品主题

#### 4.5.4.1 ads_product_info

商品个数信息，从 dwt_sku_topic 取去重后的 sku_id 和 spu_id，再统计个数。

count(distinct a) 可以转换为 select count(*) from (select a  from xxx group by  a) tmp，后者拥有更高的执行效率。

```sql
insert into table ads_product_info
select 
    '2020-04-14',
    sku_num,
    spu_num
from
(select 
    count(*) sku_num
from
(SELECT 
    sku_id
FROM dwt_sku_topic
GROUP by sku_id) t1) t3
join
(select 
    count(*) spu_num
from
(SELECT 
    spu_id
FROM dwt_sku_topic
GROUP by spu_id) t2) t4
```

#### 4.5.4.2 ads_product_sale_top10

商品销量排名： 从dws层 取  payment_num

```sql
insert into table ads_product_sale_top10
SELECT
    '2020-04-14',sku_id,payment_num
from dws_sku_action_daycount
where dt='2020-04-14'
order by payment_num desc
limit 10
```

#### 4.5.4.3 ads_product_favor_top10

商品收藏排名

```sql
insert into table ads_product_favor_top10
SELECT
    '2020-04-14',sku_id,favor_count
from dws_sku_action_daycount
where dt='2020-04-14'
order by favor_count desc
limit 10
```

#### 4.5.4.4 ads_product_cart_top10

商品加入购物车排名

```sql
insert into table ads_product_cart_top10
SELECT
    '2020-04-22',sku_id,cart_num
from dws_sku_action_daycount
where dt='2020-04-22'
order by cart_num desc
limit 10
```

#### 4.5.4.5 ads_product_refund_top10

商品退款率排名(最近30天)

最近30天的退款率= 最近30天退款的次数 /  总支付次数

从 dwt 表取  refund_last_30d_count / payment_last_30d_count

```sql
INSERT INTO TABLE ads_product_refund_top10
SELECT
    '2020-04-14',
    sku_id,
    cast (refund_last_30d_count / payment_last_30d_count * 100 as decimal(10,2)) refund_ratio
FROM dwt_sku_topic
where payment_last_30d_count>0
order by refund_ratio DESC
limit 10
```

#### 4.5.4.6 ads_appraise_bad_top10

商品差评率 = 差评数量 / 总评论数 

```sql
insert into table ads_appraise_bad_top10
SELECT
    '2020-04-22',
    sku_id,
    cast(appraise_bad_count / (appraise_good_count+appraise_bad_count+appraise_default_count+appraise_mid_count ) * 100 as decimal(10,2)) appraise_bad_ratio
FROM dwt_sku_topic
where appraise_good_count+appraise_bad_count+appraise_default_count+appraise_mid_count>0
order by appraise_bad_ratio desc
limit 10
```



### 4.5.5 营销主题（用户+商品+购买行为）

#### 4.5.5.1 ads_order_daycount

统计每日下单数，下单金额及下单用户数。从dws_user_action_daycount 取当天的所有的用户下单数据。

```sql
insert into TABLE ads_order_daycount
select 
    '2020-04-14',
    sum(order_count),
    sum(order_amount),
    sum(if(order_count>0,1,0))
from dws_user_action_daycount
where dt='2020-04-14'
```

#### 4.5.5.2 ads_payment_daycount

每日支付金额、支付人数、支付商品数、支付笔数以及下单到支付的平均时长（取自DWD）。

```sql
 dt string comment '统计日期',
 	//从dws_user_action_daycount计算
    order_count bigint comment '单日支付笔数',
    order_amount bigint comment '单日支付金额',
    payment_user_count bigint comment '单日支付人数',
    // 从dws_sku_action_daycount 取sum(payment_num)
    payment_sku_count bigint comment '单日支付商品数',
    // 从dwd_fact_order_info ，计算sum(支付时间-下单时间) / 单数 
    payment_avg_time double comment '下单到支付的平均时长，取分钟数'

```

```sql
insert into TABLE ads_payment_daycount  
SELECT
   '2020-04-14',
   order_count,order_amount,payment_user_count,payment_sku_count,payment_avg_time
FROM
(SELECT
    sum(payment_count) order_count,
    sum(payment_amount) order_amount,
    sum(if(payment_count>0,1,0)) payment_user_count
FROM  dws_user_action_daycount
where dt='2020-04-14') t1
join
(SELECT
    sum(payment_num) payment_sku_count
FROM dws_sku_action_daycount
where dt='2020-04-14') t2
join
(SELECT
    (sum(unix_timestamp(payment_time)-unix_timestamp(create_time)) / count(*) / 60) payment_avg_time
FROM dwd_fact_order_info
where dt>=date_sub('2020-04-14',1) and date_format(payment_time,'yyyy-MM-dd')='2020-04-14') t3
```

#### 4.5.5.3 ads_sale_tm_category1_stat_mn

复够率：重复购买的概率

单次复购率：  购买两次及以上的人数 / 购买单次及以上的人数(购买过的人数)

多次复购率：  购买N 次及以上的人数 / 购买N 次及以上的人数(购买过的人数)

月复够率：选取一个月的数据作为范围

```sql
 // 从dws_sale_detail_daycount取 用户信息和商品信息等
 // 按照品牌进行分组
 tm_id string comment '品牌id',
    category1_id string comment '1级品类id ',
    category1_name string comment '1级品类名称 ',
    buycount   bigint comment  '购买人数',
    buy_twice_last bigint  comment '两次以上购买人数',
    buy_twice_last_ratio decimal(10,2)  comment  '单次复购率',
    buy_3times_last   bigint comment   '三次以上购买人数',
    buy_3times_last_ratio decimal(10,2)  comment  '多次复购率',
    stat_mn string comment '统计月份',
    stat_date string comment '统计日期' 
```

① 先求出每个用户，买每个品牌，一共下了多少个单

② 将以上结果再按照品牌 id 分组，统计组内，购买单次的人数和多次的人数

```sql
insert into table ads_sale_tm_category1_stat_mn
SELECT
    sku_tm_id tm_id,sku_category1_id category1_id,sku_category1_name category1_name,
    sum(if(sum_order_count>0,1,0 )) buycount,
    sum(if(sum_order_count>1,1,0 )) buy_twice_last,
    cast(sum(if(sum_order_count>1,1,0 )) / sum(if(sum_order_count>0,1,0 )) * 100 as decimal(10,2)) buy_twice_last_ratio,
    sum(if(sum_order_count>2,1,0 )) buy_3times_last,
    cast(sum(if(sum_order_count>2,1,0 )) / sum(if(sum_order_count>0,1,0 )) * 100 as decimal(10,2)) buy_3times_last_ratio,
    date_format('2020-03-28','yyyy-MM'),
    '2020-03-28'
from 
(select 
    sku_tm_id,user_id,sku_category1_id,sku_category1_name,
    sum(order_count) sum_order_count
FROM dws_sale_detail_daycount
where date_format(dt,'yyyy-MM')=date_format('2020-03-28','yyyy-MM')
group by sku_tm_id,user_id,sku_category1_id,sku_category1_name) t1
GROUP by sku_tm_id,sku_category1_id,sku_category1_name

```

#### 4.5.5.4 ads_gmv_sum_day（后期加入）

```sql
drop table if exists ads_gmv_sum_day;
create external table ads_gmv_sum_day(
    dt string comment '统计日期',
    gmv_count bigint comment '当日GMV订单数',
    gmv_amount bigint comment '单日GMV金额',
    gmv_payment bigint comment '单日GMV支付金额'
) comment '每日订单总计表'
row format delimited fields terminated by '\t'
location '/warehouse/gmall/ads/ads_gmv_sum_day';

```

GMV = 成交总额

GMV = 所有的销售额

GMV = 所有的10w以下订单的销售额

```sql
insert into TABLE ads_gmv_sum_day
select 
'2020-04-14',
sum(order_count) gmv_count,
sum(order_amount) gmv_amount,
sum(payment_amount) gmv_payment
from dws_user_action_daycount
where dt='2020-04-14'
```

# 5. SQOOP 导出

## 5.1 MySQL 建库

手动创建 gmall_view 库，并创建表格。

## 5.2 导出至 MySQL

编写 sqoop 脚本，将 ads 层所需表中的数据导出至 MySQL。

# 6. Azkaban调度

## 6.1 azkaban 启动报错

```
Exception in thread "main" java.lang.NoClassDefFoundError: Could not initialize class org.apache.derby.jdbc.AutoloadedDriver40
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at java.sql.DriverManager.isDriverAllowed(DriverManager.java:556)
	at java.sql.DriverManager.isDriverAllowed(DriverManager.java:548)
	at java.sql.DriverManager.getDrivers(DriverManager.java:446)
	at org.apache.commons.dbcp.BasicDataSource.<clinit>(BasicDataSource.java:57)
	at azkaban.database.DataSourceUtils.getMySQLDataSource(DataSourceUtils.java:98)
	at azkaban.database.DataSourceUtils.getDataSource(DataSourceUtils.java:76)
	at azkaban.database.AbstractJdbcLoader.<init>(AbstractJdbcLoader.java:63)
	at azkaban.executor.JdbcExecutorLoader.<init>(JdbcExecutorLoader.java:59)
	at azkaban.webapp.AzkabanWebServer.loadExecutorManager(AzkabanWebServer.java:247)
	at azkaban.webapp.AzkabanWebServer.<init>(AzkabanWebServer.java:185)
	at azkaban.webapp.AzkabanWebServer.main(AzkabanWebServer.java:726)
```

解决：

```
[atguigu@hadoop103 server]$ cp /opt/module/hive/lib/derby-10.10.2.0.jar extlib/
```

## 6.2 调度思路

![image-20200415013843911](C:\Users\Jeffery\AppData\Roaming\Typora\typora-user-images\image-20200415013843911.png)

注意：如果不传 ${do_date} 参数，需要默认导入昨天的数据时，参数名需要写上，参数值不写。

# 7. 元数据管理

## 7.1 元数据

①表和库的属性信息，例如字段类型，字段名称，表的location

②表的权限，表的所属主和组等信息

③表中字段的血缘关系



create table xxx (列名 列类型, 列名 列类型)

